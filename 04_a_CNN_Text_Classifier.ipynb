{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"400\" src=\"https://www.fhnw.ch/de/++theme++web16theme/assets/media/img/fachhochschule-nordwestschweiz-fhnw-logo.svg\" alt=\"FHNW Logo\">\n",
    "\n",
    "\n",
    "# CNN Text Classifier\n",
    "\n",
    "by Fabian Märki\n",
    "\n",
    "## Summary\n",
    "The aim of this notebook is to program a CNN text classifier. Additionally, it sets the stage for a later hyperparameter tuning also allowing for model design optimization.\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/markif/2021_HS_DAS_NLP_Notebooks/blob/master/04_a_CNN_Text_Classifier.ipynb\">\n",
    "  <img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fhnw-nlp-utils>=0.1.3 in /usr/local/lib/python3.6/dist-packages (0.1.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from fhnw-nlp-utils>=0.1.3) (5.8.0)\n",
      "Requirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages (from fhnw-nlp-utils>=0.1.3) (3.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from fhnw-nlp-utils>=0.1.3) (0.24.2)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from fhnw-nlp-utils>=0.1.3) (3.6.5)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fhnw-nlp-utils>=0.1.3) (1.1.5)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fhnw-nlp-utils>=0.1.3) (3.3.4)\n",
      "Requirement already satisfied: wordcloud in /usr/local/lib/python3.6/dist-packages (from fhnw-nlp-utils>=0.1.3) (1.8.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from fhnw-nlp-utils>=0.1.3) (0.70.12.2)\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (from fhnw-nlp-utils>=0.1.3) (4.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fhnw-nlp-utils>=0.1.3) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->fhnw-nlp-utils>=0.1.3) (1.5.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->fhnw-nlp-utils>=0.1.3) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->fhnw-nlp-utils>=0.1.3) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.6/dist-packages (from nltk->fhnw-nlp-utils>=0.1.3) (2021.10.23)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk->fhnw-nlp-utils>=0.1.3) (4.62.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from nltk->fhnw-nlp-utils>=0.1.3) (8.0.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fhnw-nlp-utils>=0.1.3) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->fhnw-nlp-utils>=0.1.3) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fhnw-nlp-utils>=0.1.3) (8.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fhnw-nlp-utils>=0.1.3) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fhnw-nlp-utils>=0.1.3) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fhnw-nlp-utils>=0.1.3) (2.4.7)\n",
      "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.6/dist-packages (from multiprocess->fhnw-nlp-utils>=0.1.3) (0.3.4)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.6/dist-packages (from gdown->fhnw-nlp-utils>=0.1.3) (2.26.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from gdown->fhnw-nlp-utils>=0.1.3) (3.3.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from gdown->fhnw-nlp-utils>=0.1.3) (4.10.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown->fhnw-nlp-utils>=0.1.3) (1.15.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from click->nltk->fhnw-nlp-utils>=0.1.3) (4.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown->fhnw-nlp-utils>=0.1.3) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown->fhnw-nlp-utils>=0.1.3) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown->fhnw-nlp-utils>=0.1.3) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/lib/python3/dist-packages (from requests[socks]->gdown->fhnw-nlp-utils>=0.1.3) (2.6)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown->fhnw-nlp-utils>=0.1.3) (1.7.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.6/dist-packages (from beautifulsoup4->gdown->fhnw-nlp-utils>=0.1.3) (2.2.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->click->nltk->fhnw-nlp-utils>=0.1.3) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->click->nltk->fhnw-nlp-utils>=0.1.3) (3.7.4.3)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.6/dist-packages (5.0.0)\n",
      "Requirement already satisfied: fastparquet in /usr/local/lib/python3.6/dist-packages (0.7.1)\n",
      "Collecting fasttext\n",
      "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
      "\u001b[K     |████████████████████████████████| 68 kB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.6/dist-packages (from pyarrow) (1.19.5)\n",
      "Requirement already satisfied: cramjam>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from fastparquet) (2.4.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.6/dist-packages (from fastparquet) (2021.10.1)\n",
      "Requirement already satisfied: thrift>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from fastparquet) (0.15.0)\n",
      "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from fastparquet) (1.1.5)\n",
      "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.8.0)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (57.4.0)\n",
      "Requirement already satisfied: six>=1.7.2 in /usr/local/lib/python3.6/dist-packages (from thrift>=0.11.0->fastparquet) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.1.0->fastparquet) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.1.0->fastparquet) (2.8.2)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fasttext: filename=fasttext-0.9.2-cp36-cp36m-linux_x86_64.whl size=3123723 sha256=aea1ca770378032fecf33521f575215cf16fa33bd93bf8a03dd84c58e4f89252\n",
      "  Stored in directory: /root/.cache/pip/wheels/c3/5c/d0/4a725c6ee7df3267d818d3bc9d89bb173b94832f2b9eca6368\n",
      "Successfully built fasttext\n",
      "Installing collected packages: fasttext\n",
      "Successfully installed fasttext-0.9.2\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Tensorflow version: 2.6.0\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "!pip install 'fhnw-nlp-utils>=0.1.3'\n",
    "!pip install pyarrow fastparquet fasttext \n",
    "from fhnw.nlp.utils.storage import load_dataframe\n",
    "from fhnw.nlp.utils.storage import download\n",
    "from fhnw.nlp.utils.colab import runs_on_colab\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Tensorflow version:\", tf.__version__)\n",
    "\n",
    "#physical_devices = tf.config.list_physical_devices('GPU') \n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.7 s, sys: 2 s, total: 13.7 s\n",
      "Wall time: 7.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "download(\"https://drive.google.com/uc?id=19AFeVnOfX8WXU4_3rM7OFoNTWWog_sb_\", \"data/german_doctor_reviews_tokenized.parq\")\n",
    "data = load_dataframe(\"data/german_doctor_reviews_tokenized.parq\")\n",
    "\n",
    "download(\"https://drive.google.com/uc?id=1tT2dj70GLi2bJYg4j3g1MIglGXTDAugI\", \"data/german_doctor_reviews_augmented_tokenized.parq\")\n",
    "data_aug = load_dataframe(\"data/german_doctor_reviews_augmented_tokenized.parq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331187, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove all neutral sentimens\n",
    "data = data.loc[(data[\"label\"] != \"neutral\")]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_original</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>token_clean</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>token_lemma</th>\n",
       "      <th>token_stem</th>\n",
       "      <th>token_clean_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ich bin franzose und bin seit ein paar Wochen ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Ich bin franzose und bin seit ein paar Wochen ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>[ich, bin, franzose, und, bin, seit, ein, paar...</td>\n",
       "      <td>ich bin franzose und bin seit ein paar wochen ...</td>\n",
       "      <td>[franzose, seit, paar, wochen, muenchen, zahn,...</td>\n",
       "      <td>[franzos, seit, paar, woch, muench, ., zahn, s...</td>\n",
       "      <td>[franzose, seit, paar, wochen, muenchen, ., za...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>[dieser, arzt, ist, das, unmöglichste, was, mi...</td>\n",
       "      <td>dieser arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>[arzt, unmöglichste, leben, je, begegnen, unfr...</td>\n",
       "      <td>[arzt, unmog, leb, je, begegnet, unfreund, ,, ...</td>\n",
       "      <td>[arzt, unmöglichste, leben, je, begegnet, unfr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hatte akute Beschwerden am Rücken. Herr Magura...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hatte akute Beschwerden am Rücken. Herr Magura...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>[hatte, akute, beschwerden, am, rücken, ., her...</td>\n",
       "      <td>hatte akute beschwerden am rücken . herr magur...</td>\n",
       "      <td>[akut, beschwerden, rücken, magura, erste, arz...</td>\n",
       "      <td>[akut, beschwerd, ruck, ., magura, erst, arzt,...</td>\n",
       "      <td>[akute, beschwerden, rücken, ., magura, erste,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text_original  rating  \\\n",
       "0  Ich bin franzose und bin seit ein paar Wochen ...     2.0   \n",
       "1  Dieser Arzt ist das unmöglichste was mir in me...     6.0   \n",
       "2  Hatte akute Beschwerden am Rücken. Herr Magura...     1.0   \n",
       "\n",
       "                                                text     label  sentiment  \\\n",
       "0  Ich bin franzose und bin seit ein paar Wochen ...  positive          1   \n",
       "1  Dieser Arzt ist das unmöglichste was mir in me...  negative         -1   \n",
       "2  Hatte akute Beschwerden am Rücken. Herr Magura...  positive          1   \n",
       "\n",
       "                                         token_clean  \\\n",
       "0  [ich, bin, franzose, und, bin, seit, ein, paar...   \n",
       "1  [dieser, arzt, ist, das, unmöglichste, was, mi...   \n",
       "2  [hatte, akute, beschwerden, am, rücken, ., her...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  ich bin franzose und bin seit ein paar wochen ...   \n",
       "1  dieser arzt ist das unmöglichste was mir in me...   \n",
       "2  hatte akute beschwerden am rücken . herr magur...   \n",
       "\n",
       "                                         token_lemma  \\\n",
       "0  [franzose, seit, paar, wochen, muenchen, zahn,...   \n",
       "1  [arzt, unmöglichste, leben, je, begegnen, unfr...   \n",
       "2  [akut, beschwerden, rücken, magura, erste, arz...   \n",
       "\n",
       "                                          token_stem  \\\n",
       "0  [franzos, seit, paar, woch, muench, ., zahn, s...   \n",
       "1  [arzt, unmog, leb, je, begegnet, unfreund, ,, ...   \n",
       "2  [akut, beschwerd, ruck, ., magura, erst, arzt,...   \n",
       "\n",
       "                               token_clean_stopwords  \n",
       "0  [franzose, seit, paar, wochen, muenchen, ., za...  \n",
       "1  [arzt, unmöglichste, leben, je, begegnet, unfr...  \n",
       "2  [akute, beschwerden, rücken, ., magura, erste,...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_original</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>token_clean</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>token_lemma</th>\n",
       "      <th>token_stem</th>\n",
       "      <th>token_clean_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[dieser, arzt, ist, das, unmöglichste, was, mi...</td>\n",
       "      <td>dieser arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>[arzt, unmöglichste, leben, je, begegnen, unfr...</td>\n",
       "      <td>[arzt, unmog, leb, je, begegnet, unfreund, ,, ...</td>\n",
       "      <td>[arzt, unmöglichste, leben, je, begegnet, unfr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[dieser, arzt, ist, das, unmöglichste, was, mi...</td>\n",
       "      <td>dieser arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>[arzt, unmöglichste, leben, je, begegnen, unfr...</td>\n",
       "      <td>[arzt, unmog, leb, je, begegnet, unfreund, ,, ...</td>\n",
       "      <td>[arzt, unmöglichste, leben, je, begegnet, unfr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[dieser, arzt, ist, das, unmöglichste, was, mi...</td>\n",
       "      <td>dieser arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>[arzt, unmöglichste, leben, je, begegnen, unfr...</td>\n",
       "      <td>[arzt, unmog, leb, je, begegnet, unfreund, ,, ...</td>\n",
       "      <td>[arzt, unmöglichste, leben, je, begegnet, unfr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text_original  rating  sentiment  \\\n",
       "1  Dieser Arzt ist das unmöglichste was mir in me...     6.0         -1   \n",
       "1  Dieser Arzt ist das unmöglichste was mir in me...     6.0         -1   \n",
       "1  Dieser Arzt ist das unmöglichste was mir in me...     6.0         -1   \n",
       "\n",
       "                                                text     label  \\\n",
       "1  Dieser Arzt ist das unmöglichste was mir in me...  negative   \n",
       "1  Dieser Arzt ist das unmöglichste was mir in me...  negative   \n",
       "1  Dieser Arzt ist das unmöglichste was mir in me...  negative   \n",
       "\n",
       "                                         token_clean  \\\n",
       "1  [dieser, arzt, ist, das, unmöglichste, was, mi...   \n",
       "1  [dieser, arzt, ist, das, unmöglichste, was, mi...   \n",
       "1  [dieser, arzt, ist, das, unmöglichste, was, mi...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "1  dieser arzt ist das unmöglichste was mir in me...   \n",
       "1  dieser arzt ist das unmöglichste was mir in me...   \n",
       "1  dieser arzt ist das unmöglichste was mir in me...   \n",
       "\n",
       "                                         token_lemma  \\\n",
       "1  [arzt, unmöglichste, leben, je, begegnen, unfr...   \n",
       "1  [arzt, unmöglichste, leben, je, begegnen, unfr...   \n",
       "1  [arzt, unmöglichste, leben, je, begegnen, unfr...   \n",
       "\n",
       "                                          token_stem  \\\n",
       "1  [arzt, unmog, leb, je, begegnet, unfreund, ,, ...   \n",
       "1  [arzt, unmog, leb, je, begegnet, unfreund, ,, ...   \n",
       "1  [arzt, unmog, leb, je, begegnet, unfreund, ,, ...   \n",
       "\n",
       "                               token_clean_stopwords  \n",
       "1  [arzt, unmöglichste, leben, je, begegnet, unfr...  \n",
       "1  [arzt, unmöglichste, leben, je, begegnet, unfr...  \n",
       "1  [arzt, unmöglichste, leben, je, begegnet, unfr...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aug.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split(params, data):\n",
    "    \"\"\"Performs a train/test split based on the provided params\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        The dictionary containing the parameters\n",
    "    data: dataframe\n",
    "        The data\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "        A tuple with the train/test data\n",
    "    \"\"\"\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "        \n",
    "    verbose = params.get(\"verbose\", False)\n",
    "    split_size = params.get(\"train_test_split_size\", 0.2)\n",
    "    y_column_name = params.get(\"y_column_name\", \"label\")\n",
    "    \n",
    "    data_train, data_test = train_test_split(data, test_size=split_size, shuffle=True, random_state=42, stratify=data[y_column_name])\n",
    "\n",
    "    if verbose:\n",
    "        print(len(data_train), 'train examples')\n",
    "        print(len(data_test), 'test examples')\n",
    "        \n",
    "    return (data_train, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_type_and_set(params, data):\n",
    "    \"\"\"Determines the classification type based on what the user defined or inferred by the labels\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        The dictionary containing the parameters\n",
    "    data: dataframe\n",
    "        The data\n",
    "    \"\"\"\n",
    "    \n",
    "    verbose = params.get(\"verbose\", False)\n",
    "    classification_type = params.get(\"classification_type\", None)\n",
    "    y_column_name = params.get(\"y_column_name\", \"label\")\n",
    "    \n",
    "    if classification_type is None:\n",
    "        if len(data[y_column_name].shape) > 1:\n",
    "            classification_type = \"multi-label\"\n",
    "        elif len(data[y_column_name].unique()) > 2:\n",
    "            classification_type = \"multi-class\"\n",
    "        else:\n",
    "            classification_type = \"binary\"\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Inferred classification type:\", classification_type)\n",
    "        \n",
    "        params[\"classification_type\"] = classification_type\n",
    "            \n",
    "    return classification_type \n",
    "\n",
    "\n",
    "def create_label_binarizer_and_set(params, data):\n",
    "    \"\"\"Creates an initialized LabelBinarizer\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        The dictionary containing the parameters\n",
    "    data: dataframe\n",
    "        The data\n",
    "    \"\"\"\n",
    "    \n",
    "    from sklearn.preprocessing import LabelBinarizer\n",
    "    from sklearn.preprocessing import MultiLabelBinarizer\n",
    "    \n",
    "    y_column_name = params.get(\"y_column_name\", \"label\")\n",
    "    computed_objects_column_name = params.get(\"computed_objects_column_name\", \"computed_objects\")\n",
    "    classification_type = get_classification_type_and_set(params, data)\n",
    "    \n",
    "    if classification_type == \"multi-label\":\n",
    "        label_binarizer = MultiLabelBinarizer()\n",
    "        _ = label_binarizer.fit(data[y_column_name])\n",
    "    else: \n",
    "        label_binarizer = LabelBinarizer()\n",
    "        _ = label_binarizer.fit(data[y_column_name])\n",
    "    \n",
    "    params.setdefault(computed_objects_column_name, {})[\"label_binarizer\"] = label_binarizer\n",
    "\n",
    "    \n",
    "def dataframe_to_dataset(params, data):\n",
    "    \"\"\"Converts a dataframe into a dataset\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        The dictionary containing the parameters\n",
    "    data: dataframe\n",
    "        The data\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dataset\n",
    "        The dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    \n",
    "    shuffle = params.get(\"shuffle\", True)\n",
    "    batch_size = params.get(\"batch_size\", 64)\n",
    "    X_column_name = params.get(\"X_column_name\", \"text_clean\")\n",
    "    y_column_name = params.get(\"y_column_name\", \"label\")\n",
    "    computed_objects_column_name = params.get(\"computed_objects_column_name\", \"computed_objects\")\n",
    "    label_binarizer = params.setdefault(computed_objects_column_name, {})[\"label_binarizer\"]\n",
    "    \n",
    "    data = data.drop(data.columns.difference([X_column_name, y_column_name]), 1, inplace=False)\n",
    "    y = data.pop(y_column_name)\n",
    "    y = label_binarizer.transform(y)\n",
    "    output_classes = len(label_binarizer.classes_)\n",
    "    if output_classes <= 2:\n",
    "        y = y.flatten()\n",
    "    \n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(data), y))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(data))\n",
    "    \n",
    "    # ds = ds.cache()\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vocabulary_and_set(params, data):\n",
    "    \"\"\"Extracts the vocabulary and puts it into the params dictionary\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        The dictionary containing the parameters\n",
    "    data: dataframe\n",
    "        The data\n",
    "    \"\"\"\n",
    "    \n",
    "    verbose = params.get(\"verbose\", False)\n",
    "    tokenized_column = params.get(\"tokenized_column\", \"token_clean\")\n",
    "    sequence_length_percentil_cutoff = params.get(\"sequence_length_percentil_cutoff\", 0.98)\n",
    "    sequence_length_max = params.get(\"sequence_length_max\", 768)\n",
    "    computed_objects_column_name = params.get(\"computed_objects_column_name\", \"computed_objects\")\n",
    "    X = data[tokenized_column]\n",
    "\n",
    "    vocabulary = set()\n",
    "    _ = X.apply(lambda x: vocabulary.update(x))\n",
    "\n",
    "    lengths = X.apply(len)\n",
    "    max_sequence_length = int(lengths.quantile(1.0))\n",
    "    percentil_sequence_length = int(lengths.quantile(0.98))\n",
    "    median_sequence_length = int(lengths.quantile(0.5))\n",
    "    embedding_input_sequence_length = min(sequence_length_max, percentil_sequence_length)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Median sequence length:\", median_sequence_length)\n",
    "        print(\"Percentil (\", sequence_length_percentil_cutoff, \") cutoff sequence length: \", percentil_sequence_length, sep='')\n",
    "        print(\"Max sequence length:\", max_sequence_length)\n",
    "        print(\"Used embedding sequence length:\", embedding_input_sequence_length)\n",
    "\n",
    "    params.setdefault(computed_objects_column_name, {})[\"vocabulary\"] = vocabulary\n",
    "    params[\"embedding_input_sequence_length\"] = embedding_input_sequence_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras TextVectorization layer\n",
    "Keras has an experimental text preprocessing layer than can be placed before an embedding layer. In total, it allows documents of various sizes to be passed to the model. The TextVectorization layer will tokenize, vectorize, and pad sequences representing those documents to be passed to the embedding layer. It can also be used as an integer index to tell the embedding layer which integer encoded words represent which embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_vectorization_and_set(params):\n",
    "    \"\"\"Creates the TextVectorization layer and a vocabulary iterator and puts them into the params dictionary\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        The dictionary containing the parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "    # for newer versions use\n",
    "    #from tensorflow.keras.layers import TextVectorization\n",
    "    # see https://towardsdatascience.com/you-should-try-the-new-tensorflows-textvectorization-layer-a80b3c6b00ee\n",
    "\n",
    "    verbose = params.get(\"verbose\", False)\n",
    "    output_sequence_length = params.get(\"output_sequence_length\", None)\n",
    "    computed_objects_column_name = params.get(\"computed_objects_column_name\", \"computed_objects\")\n",
    "    vocabulary = params.setdefault(computed_objects_column_name, {})[\"vocabulary\"]\n",
    "    \n",
    "    vectorize_layer = TextVectorization(\n",
    "        output_mode='int',\n",
    "        output_sequence_length=output_sequence_length,\n",
    "        vocabulary=list(vocabulary),\n",
    "        name=\"text_vectorization\"\n",
    "    )\n",
    "    \n",
    "    params.setdefault(computed_objects_column_name, {})[\"vocabulary_iterator\"] = vectorize_layer.get_vocabulary()\n",
    "    params.setdefault(computed_objects_column_name, {})[\"vectorize_layer\"] = vectorize_layer\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Vocabulary length:\", vectorize_layer.vocabulary_size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the Embedding Dictionary to an Embedding Layer\n",
    "If you want to use someone else's trained embeddings in your model, you will need to create a mapping from the word indices the TextVectorizer layer uses to encode your vocabulary to the word embedding vectors from your embedding dictionary.\n",
    "\n",
    "The embedding layer will look at the index integer for each word in the passed by the TextVectorizer, use that to look up the embedding, then pass the embeddings of each word in the input sequence to the next layer. The index position of each word in the vocabulary list returned by TextVectorizer.get_vocabulary() is also the encoding that the TextVectorizer will return for each word. We will next create the weights matrix we will use to initialize the embedding layer. We do this by looping over the words in the TextVectorizer vocabulary and the embedding dictionary. Each word encoding from the TextVectorizer will be a row index in the weights matrix and the vector accessed for that word will be the one from the embedding dictionary we chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedder(params):\n",
    "    \"\"\"Provides the embedder based on the params\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        The dictionary containing the parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    embedding_type = params[\"embedding_type\"]\n",
    "    if embedding_type == \"fasttext\":\n",
    "        return get_embedder_fasttext(params)\n",
    "    if embedding_type == \"word2vec\":\n",
    "        return get_embedder_word2vec(params)\n",
    "    if embedding_type == \"spacy\":\n",
    "        return get_embedder_spacy(params)\n",
    "    if embedding_type == \"tensorflow_hub\":\n",
    "        return get_embedder_tensorflow_hub(params)\n",
    "    if embedding_type == \"bytepair\":\n",
    "        return get_embedder_byte_pair(params)\n",
    "    else:\n",
    "        raise TypeError(\"Unknown embedding_type \"+ embedding_type)\n",
    "\n",
    "def get_embedder_fasttext(params):\n",
    "    \"\"\"Provides the fasttext embedder\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        The dictionary containing the parameters\n",
    "    \"\"\"\n",
    "        \n",
    "    import fasttext\n",
    "    import fasttext.util\n",
    "\n",
    "    embedding_dim = params[\"embedding_dim\"]\n",
    "    model_name = params[\"embedding_fasttext_model\"]\n",
    "    split = model_name.split(\".\")\n",
    "    model_lang = split[1]\n",
    "    model_dim = int(split[2])\n",
    "    \n",
    "    try:\n",
    "        ft = fasttext.load_model(model_name)\n",
    "    except ValueError:\n",
    "        fasttext.util.download_model(model_lang, if_exists='ignore')\n",
    "        ft = fasttext.load_model(model_name)\n",
    "    \n",
    "    if embedding_dim < model_dim:\n",
    "        fasttext.util.reduce_model(ft, embedding_dim)\n",
    "    \n",
    "    def fasttext_embedder(word):\n",
    "        return ft.get_word_vector(word)\n",
    "    \n",
    "    return fasttext_embedder\n",
    "\n",
    "\n",
    "def get_embedder_byte_pair(params):\n",
    "    \"\"\"Provides the byte pair embedder\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        The dictionary containing the parameters\n",
    "    \"\"\"\n",
    "        \n",
    "    from bpemb import BPEmb\n",
    "    import numpy as np\n",
    "\n",
    "    embedding_lang = params.get(\"embedding_lang\", \"de\")\n",
    "    \n",
    "    bpemb = BPEmb(lang=embedding_lang)\n",
    "    \n",
    "    def byte_pair_embedder(word, order=2):\n",
    "        vec = bpemb.embed(word).sum(axis=0)\n",
    "        l2 = np.atleast_1d(np.linalg.norm(vec, order))\n",
    "        l2[l2==0] = 1\n",
    "        #return vec / np.expand_dims(l2, axis)\n",
    "        return vec / l2\n",
    "    \n",
    "    return byte_pair_embedder\n",
    "\n",
    "\n",
    "def get_embedder_word2vec(params):\n",
    "    \"\"\"Provides the word2vec embedder\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        The dictionary containing the parameters\n",
    "    \"\"\"\n",
    "        \n",
    "    import os\n",
    "    import gensim\n",
    "    \n",
    "    model_url = params[\"embedding_word2vec_model_url\"]\n",
    "    model_path = \"models/word2vec/\"+os.path.basename(model_url)\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        download(url=model_url, path = model_path)\n",
    "        \n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=True)\n",
    "    \n",
    "    def word2vec_embedder(word):\n",
    "        try:\n",
    "            return model[word]\n",
    "        except KeyError:\n",
    "            return None\n",
    "    \n",
    "    return word2vec_embedder\n",
    "\n",
    "\n",
    "def get_embedder_spacy(params):\n",
    "    \"\"\"Provides the spacy embedder\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        The dictionary containing the parameters\n",
    "    \"\"\"\n",
    "        \n",
    "    import spacy\n",
    "    \n",
    "    model_name = params[\"embedding_spacy_model\"]\n",
    "    \n",
    "    try:\n",
    "        nlp = spacy.load(model_name)\n",
    "    except OSError:\n",
    "        from spacy.cli import download\n",
    "        \n",
    "        download(model_name)\n",
    "        nlp = spacy.load(model_name)\n",
    "    \n",
    "    def spacy_embedder(word):\n",
    "        return nlp(word)[0].vector\n",
    "    \n",
    "    return spacy_embedder\n",
    "\n",
    "\n",
    "def get_embedder_tensorflow_hub(params):\n",
    "    \"\"\"Provides the tensorflow embedder\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        The dictionary containing the parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    import tensorflow_hub as hub\n",
    "    \n",
    "    embedding_url = params[\"embedding_tensorflow_hub_url\"]\n",
    "    \n",
    "    embed = hub.load(embedding_url)\n",
    "    \n",
    "    def tensorflow_hub_embedder(word):\n",
    "        return embed([word])[0].numpy()\n",
    "    \n",
    "    return tensorflow_hub_embedder\n",
    "\n",
    "\n",
    "def calculate_embedding_matrix(params, embedder):\n",
    "    \"\"\"Creates the embedding matrix\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        The dictionary containing the parameters\n",
    "    embedder: function\n",
    "        The function to get the embedding for a word\n",
    "    \"\"\"    \n",
    "    \n",
    "    import numpy as np\n",
    "\n",
    "    computed_objects_column_name = params.get(\"computed_objects_column_name\", \"computed_objects\")\n",
    "    vocabulary_iterator = params.setdefault(computed_objects_column_name, {})[\"vocabulary_iterator\"]\n",
    "    tmp_embedding = embedder(\"haus\")\n",
    "    \n",
    "    if (tmp_embedding is not None) and len(tmp_embedding) > 0:\n",
    "        embedding_dim = len(tmp_embedding)\n",
    "    else:\n",
    "        embedding_dim = params[\"embedding_dim\"]\n",
    "    voc_size = len(vocabulary_iterator)\n",
    "    words_not_found = set()\n",
    "    embedding_matrix = np.zeros((voc_size, embedding_dim))\n",
    "\n",
    "    for idx, word in enumerate(vocabulary_iterator):\n",
    "        embedding_vector = embedder(word)\n",
    "        if (embedding_vector is not None) and len(embedding_vector) > 0 and not np.all(embedding_vector==0):\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[idx] = embedding_vector\n",
    "        else:\n",
    "            words_not_found.add(word)\n",
    "\n",
    "    if params[\"verbose\"]:\n",
    "        print(\"Embedding type:\", params.get(\"embedding_type\"))\n",
    "        print(\"Number of null word embeddings:\", np.sum(np.sum(embedding_matrix, axis=1) == 0))\n",
    "        nr_words_not_found = len(words_not_found)\n",
    "        print(\"Words not found in total:\", len(words_not_found))\n",
    "        if nr_words_not_found > 0:\n",
    "            import random\n",
    "            \n",
    "            nr_sample = min(20, len(words_not_found))\n",
    "            print(\"Words without embedding (\", nr_sample, \"/\", nr_words_not_found, \"): \", random.sample(words_not_found, nr_sample), sep='')\n",
    "    \n",
    "    return embedding_matrix\n",
    "\n",
    "\n",
    "def extract_embedding_layer_and_set(params):\n",
    "    \"\"\"Creates the Embedding layer and puts it into the params dictionary\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        The dictionary containing the parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from fhnw.nlp.utils.params import install_dependencies\n",
    "    \n",
    "    computed_objects_column_name = params.get(\"computed_objects_column_name\", \"computed_objects\")\n",
    "    \n",
    "    install_dependencies(params)\n",
    "    \n",
    "    embedding_type = params.get(\"embedding_type\")\n",
    "    if embedding_type is not None:\n",
    "        if embedding_type == \"tensorflow_hub_layer\":\n",
    "            import tensorflow_hub as hub\n",
    "            \n",
    "            embedding_url = params[\"embedding_tensorflow_hub_url\"]\n",
    "            embedding_layer = hub.KerasLayer(embedding_url, input_shape=[], dtype=tf.string, trainable=params[\"embedding_trainable\"], name=\"hub_embedding\")\n",
    "        else:\n",
    "            embedder = get_embedder(params)       \n",
    "            embedding_matrix = calculate_embedding_matrix(params, embedder)       \n",
    "            embedding_layer = keras.layers.Embedding(\n",
    "                                          embedding_matrix.shape[0], \n",
    "                                          embedding_matrix.shape[1], \n",
    "                                          weights=[embedding_matrix],\n",
    "                                          input_length=params[\"embedding_input_sequence_length\"],\n",
    "                                          trainable=params[\"embedding_trainable\"],\n",
    "                                          mask_zero = params[\"embedding_mask_zero\"],\n",
    "                                          name=\"embedding\"\n",
    "                                         )\n",
    "    else:\n",
    "        embedding_layer = keras.layers.Embedding(\n",
    "                                                 len(params[\"vocabulary_iterator\"]), \n",
    "                                                 params[\"embedding_dim\"], \n",
    "                                                 mask_zero = params[\"embedding_mask_zero\"], \n",
    "                                                 trainable=True)\n",
    "        \n",
    "    params.setdefault(computed_objects_column_name, {})[\"embedding_layer\"] = embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"verbose\": True,\n",
    "    \"shuffle\": True,\n",
    "    \"batch_size\": 128,\n",
    "    \"X_column_name\": \"text_clean\",\n",
    "    \"y_column_name\": \"label\",\n",
    "    \"embedding_type\": \"fasttext\",\n",
    "    #\"embedding_type\": \"bytepair\",\n",
    "    \"embedding_dim\": 300,\n",
    "    \"embedding_mask_zero\": True,\n",
    "    \"embedding_trainable\": False,\n",
    "    #\"embedding_input_sequence_length\": output_sequence_length if 'output_sequence_length' in locals() or 'output_sequence_length' in globals() else None,\n",
    "    \"embedding_fasttext_model\": \"cc.de.300.bin\",\n",
    "    \"embedding_word2vec_model_url\": \"https://cloud.devmount.de/d2bc5672c523b086/german.model\",\n",
    "    \"embedding_spacy_model\": \"de_core_news_md\",\n",
    "    \"embedding_tensorflow_hub_url\": \"https://tfhub.dev/google/nnlm-de-dim128-with-normalization/2\",\n",
    "    \"cnn_num_conv_pooling_layers\": 2,\n",
    "    \"model_type\": \"cnn\",\n",
    "}\n",
    "\n",
    "if runs_on_colab() and params[\"embedding_type\"] == \"fasttext\":\n",
    "    # colab as problems handling such large files\n",
    "    model_name = \"cc.de.50.bin\"\n",
    "    download(\"https://drive.google.com/uc?id=1iqw8UPEEVmzQQGmI5FkRJH8B5SkZCgXG\", model_name)\n",
    "    params[\"embedding_dim\"] = 50\n",
    "    params[\"embedding_fasttext_model\"] = model_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([data, data_aug])\n",
    "#all_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred classification type: binary\n",
      "Median sequence length: 58\n",
      "Percentil (0.98) cutoff sequence length: 301\n",
      "Max sequence length: 408\n",
      "Used embedding sequence length: 301\n"
     ]
    }
   ],
   "source": [
    "create_label_binarizer_and_set(params, all_data)\n",
    "extract_vocabulary_and_set(params, all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length: 205493\n"
     ]
    }
   ],
   "source": [
    "extract_text_vectorization_and_set(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "extract_embedding_layer_and_set(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some words suggest that there still exist none german/corrupt text..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_original</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>token_clean</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>token_lemma</th>\n",
       "      <th>token_stem</th>\n",
       "      <th>token_clean_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>Heute war ich zum ersten Mal gemeinsam mit mei...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Heute war ich zum ersten Mal gemeinsam mit mei...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>[heute, war, ich, zum, ersten, mal, gemeinsam,...</td>\n",
       "      <td>heute war ich zum ersten mal gemeinsam mit mei...</td>\n",
       "      <td>[heute, erst, mal, gemeinsam, jährig, tochter,...</td>\n",
       "      <td>[heut, erst, mal, gemeinsam, jahrig, tocht, pr...</td>\n",
       "      <td>[heute, ersten, mal, gemeinsam, jährigen, toch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text_original  rating  \\\n",
       "3264  Heute war ich zum ersten Mal gemeinsam mit mei...     1.0   \n",
       "\n",
       "                                                   text     label  sentiment  \\\n",
       "3264  Heute war ich zum ersten Mal gemeinsam mit mei...  positive          1   \n",
       "\n",
       "                                            token_clean  \\\n",
       "3264  [heute, war, ich, zum, ersten, mal, gemeinsam,...   \n",
       "\n",
       "                                             text_clean  \\\n",
       "3264  heute war ich zum ersten mal gemeinsam mit mei...   \n",
       "\n",
       "                                            token_lemma  \\\n",
       "3264  [heute, erst, mal, gemeinsam, jährig, tochter,...   \n",
       "\n",
       "                                             token_stem  \\\n",
       "3264  [heut, erst, mal, gemeinsam, jahrig, tocht, pr...   \n",
       "\n",
       "                                  token_clean_stopwords  \n",
       "3264  [heute, ersten, mal, gemeinsam, jährigen, toch...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"text_clean\"].str.contains(pat = ' úm ')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... seems to be ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_cnn_simple(params):\n",
    "    \"\"\"Builds a simple cnn classifier (only partially) based on the provided params \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        The dictionary containing the parameters\n",
    "    \"\"\"\n",
    "        \n",
    "    from tensorflow import keras\n",
    "    \n",
    "    classification_type = params.get(\"classification_type\", \"binary\")\n",
    "    if classification_type == \"binary\":\n",
    "        output_activation = \"sigmoid\"\n",
    "    elif classification_type == \"multi-class\":\n",
    "        output_activation = \"softmax\"\n",
    "    elif classification_type == \"multi-label\":\n",
    "        output_activation = \"sigmoid\"\n",
    "    else:\n",
    "        raise TypeError(\"Unknown classification_type \"+classification_type)\n",
    "    \n",
    "    computed_objects_column_name = params.get(\"computed_objects_column_name\", \"computed_objects\")\n",
    "    vectorize_layer = params[computed_objects_column_name][\"vectorize_layer\"]\n",
    "    embedding_layer = params[computed_objects_column_name][\"embedding_layer\"]\n",
    "    label_binarizer = params[computed_objects_column_name][\"label_binarizer\"]\n",
    "    output_classes = len(label_binarizer.classes_)\n",
    "    output_classes = output_classes if output_classes > 2 else 1\n",
    "    \n",
    "    \n",
    "    model = keras.Sequential(name=\"cnn\")\n",
    "    # A text input\n",
    "    model.add(keras.layers.InputLayer(input_shape=(1,), dtype=tf.string, name=\"text_input\"))\n",
    "    # The first layer in our model is the vectorization layer. After this layer,\n",
    "    # we have a tensor of shape (batch_size, output_sequence_length) containing vocab indices.\n",
    "    model.add(vectorize_layer)\n",
    "    # Next, we add a layer to map those vocab indices into a space of dimensionality 'embedding_dim'. \n",
    "    model.add(embedding_layer)\n",
    "    \n",
    "    cnn_conv_num_filters = 128\n",
    "    cnn_conv_kernel_size = 7\n",
    "    model.add(keras.layers.Conv1D(\n",
    "        cnn_conv_num_filters, \n",
    "        cnn_conv_kernel_size, \n",
    "        activation=\"relu\", \n",
    "        strides=1, \n",
    "        padding=\"valid\", # valid -> no padding, same -> zeros so that output has same dimensions\n",
    "        name=\"conv_1\"))\n",
    "    \n",
    "    model.add(keras.layers.GlobalMaxPooling1D(name=\"global_max_pool_1\"))\n",
    "\n",
    "    # do not forget Dropout (regularization) for a more sophisticated model\n",
    "    model.add(keras.layers.Dense(output_classes, activation=output_activation, name=\"prediction\"))\n",
    "    \n",
    "    return model\n",
    "    \n",
    "\n",
    "def build_model_cnn(params):\n",
    "    \"\"\"Builds a cnn classifier based on the provided params \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        The dictionary containing the parameters\n",
    "    \"\"\"\n",
    "        \n",
    "    from tensorflow import keras\n",
    "    \n",
    "    cnn_num_conv_pooling_layers = params.get(\"cnn_num_conv_pooling_layers\", 2)\n",
    "    cnn_conv_num_filters = params.get(\"cnn_conv_num_filters\", 128)\n",
    "    cnn_conv_kernel_size = params.get(\"cnn_conv_kernel_size\", 7)\n",
    "    cnn_conv_activation_function = params.get(\"cnn_conv_activation_function\", \"relu\")\n",
    "    cnn_conv_strides = params.get(\"cnn_conv_strides\", 1)\n",
    "    cnn_conv_padding = params.get(\"cnn_conv_padding\", \"valid\")\n",
    "    cnn_max_pool_size = params.get(\"cnn_max_pool_size\", 2)\n",
    "    cnn_max_pool_strides = params.get(\"cnn_max_pool_strides\", None)\n",
    "    cnn_max_pool_padding = params.get(\"cnn_max_pool_padding\", \"valid\")\n",
    "    cnn_global_max_pool_dropout = params.get(\"cnn_global_max_pool_dropout\", 0.5)\n",
    "    cnn_dense_units = params.get(\"cnn_dense_units\", 128)\n",
    "    cnn_dense_activation_function = params.get(\"cnn_dense_activation_function\", \"relu\")\n",
    "    cnn_output_dropout = params.get(\"cnn_output_dropout\", 0.5)\n",
    "    \n",
    "    classification_type = params.get(\"classification_type\", \"binary\") \n",
    "    \n",
    "    computed_objects_column_name = params.get(\"computed_objects_column_name\", \"computed_objects\")\n",
    "    vectorize_layer = params[computed_objects_column_name][\"vectorize_layer\"]\n",
    "    embedding_layer = params[computed_objects_column_name][\"embedding_layer\"]\n",
    "    label_binarizer = params[computed_objects_column_name][\"label_binarizer\"]\n",
    "    output_classes = len(label_binarizer.classes_)\n",
    "    output_classes = output_classes if output_classes > 2 else 1\n",
    "    \n",
    "    model = keras.Sequential(name=\"cnn\")\n",
    "    # A text input\n",
    "    model.add(keras.layers.InputLayer(input_shape=(1,), dtype=tf.string, name=\"text_input\"))\n",
    "    # The first layer in our model is the vectorization layer. After this layer,\n",
    "    # we have a tensor of shape (batch_size, output_sequence_length) containing vocab indices.\n",
    "    model.add(vectorize_layer)\n",
    "    # Next, we add a layer to map those vocab indices into a space of dimensionality 'embedding_dim'. \n",
    "    model.add(embedding_layer)\n",
    "    \n",
    "    for layer in range(cnn_num_conv_pooling_layers):\n",
    "        model.add(keras.layers.Conv1D(cnn_conv_num_filters, cnn_conv_kernel_size, activation=cnn_conv_activation_function, strides=cnn_conv_strides, padding=cnn_conv_padding, name=\"conv_\"+str(layer)))\n",
    "        \n",
    "        if layer + 1 < cnn_num_conv_pooling_layers:\n",
    "            model.add(keras.layers.MaxPooling1D(pool_size=cnn_max_pool_size, strides=cnn_max_pool_strides, padding=cnn_max_pool_padding, name=\"max_pool_\"+str(layer)))\n",
    "        else:\n",
    "            model.add(keras.layers.GlobalMaxPooling1D(name=\"global_max_pool_\"+str(layer)))\n",
    "    \n",
    "    \n",
    "    if cnn_global_max_pool_dropout is not None and cnn_global_max_pool_dropout > 0 and cnn_num_conv_pooling_layers > 0:\n",
    "        model.add(keras.layers.Dropout(cnn_global_max_pool_dropout, name=\"global_max_pool_dropout\"))\n",
    "    \n",
    "    model.add(keras.layers.Dense(cnn_dense_units, activation=cnn_dense_activation_function, name=\"dense\"))\n",
    "    \n",
    "    \n",
    "    if cnn_output_dropout is not None and cnn_output_dropout > 0:\n",
    "        model.add(keras.layers.Dropout(cnn_output_dropout, name=\"dense_dropout\"))\n",
    "\n",
    "    \n",
    "    if classification_type == \"binary\":\n",
    "        output_activation = \"sigmoid\"\n",
    "    elif classification_type == \"multi-class\":\n",
    "        output_activation = \"softmax\"\n",
    "    elif classification_type == \"multi-label\":\n",
    "        output_activation = \"sigmoid\"\n",
    "    else:\n",
    "        raise TypeError(\"Unknown classification_type \"+classification_type)\n",
    "\n",
    "    model.add(keras.layers.Dense(output_classes, activation=output_activation, name=\"prediction\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def get_loss_function(params):\n",
    "    \"\"\"Decides upon the loss function to use based on the provided params\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        The dictionary containing the parameters\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The name of the loss function (or a callable)\n",
    "    \"\"\"\n",
    "        \n",
    "    classification_type = params.get(\"classification_type\", \"binary\")\n",
    "    \n",
    "    if classification_type == \"binary\":\n",
    "        model_loss_function = \"binary_crossentropy\"\n",
    "    elif classification_type == \"multi-class\":\n",
    "        model_loss_function = \"categorical_crossentropy\"\n",
    "    elif classification_type == \"multi-label\":\n",
    "        model_loss_function = \"binary_crossentropy\"\n",
    "    else:\n",
    "        raise TypeError(\"Unknown classification_type \"+classification_type)\n",
    "    \n",
    "    return model_loss_function\n",
    "\n",
    "\n",
    "def get_model_metric(params):\n",
    "    \"\"\"Provides the metric based on the provided params\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        The dictionary containing the parameters\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        The list of metrics to use\n",
    "    \"\"\"\n",
    "    \n",
    "    return params.get(\"model_metric\", [\"accuracy\"])\n",
    "\n",
    "\n",
    "def compile_model(params, model):\n",
    "    \"\"\"Compiles the model based on the provided params \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        The dictionary containing the parameters\n",
    "    model: model\n",
    "        The keras model\n",
    "    \"\"\"\n",
    "    \n",
    "    from tensorflow import keras\n",
    "        \n",
    "    optimizer_learning_rate = params.get(\"learning_rate\", 0.01)\n",
    "    optimizer_learning_rate_decay = params.get(\"optimizer_learning_rate_decay\", None)\n",
    "    model_metric = get_model_metric(params)\n",
    "    model_loss_function = get_loss_function(params)\n",
    "\n",
    "    adam = keras.optimizers.Adam(learning_rate=optimizer_learning_rate)\n",
    "    if optimizer_learning_rate_decay is not None:\n",
    "        adam = keras.optimizers.Adam(learning_rate=optimizer_learning_rate, decay=optimizer_learning_rate_decay)\n",
    "\n",
    "    model.compile(loss=model_loss_function, optimizer=adam, metrics=model_metric)\n",
    "    \n",
    "    \n",
    "def re_compile_model(params, model):\n",
    "    \"\"\"Re-compiles the model based on the provided params and the existing optimizer \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        The dictionary containing the parameters\n",
    "    model: model\n",
    "        The keras model\n",
    "    \"\"\"\n",
    "    \n",
    "    from tensorflow import keras\n",
    "    \n",
    "    # use a low learning rate for fine tuning\n",
    "    optimizer_learning_rate = params.get(\"learning_rate\", 1e-5)\n",
    "    model_metric = get_model_metric(params)\n",
    "    model_loss_function = get_loss_function(params)\n",
    "    \n",
    "    # keep existing internal parameters for further runs\n",
    "    optimizer = model.optimizer\n",
    "    optimizer.learning_rate.assign(optimizer_learning_rate)\n",
    "\n",
    "    model.compile(loss=model_loss_function, optimizer=optimizer, metrics=model_metric)\n",
    "\n",
    "\n",
    "def train_model(params, model, dataset_train, dataset_val):\n",
    "    \"\"\"Performs the model training \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        The dictionary containing the parameters\n",
    "    model: model\n",
    "        The keras model\n",
    "    dataset_train: tf Dataset\n",
    "        The dataset for training\n",
    "    dataset_val; tf Dataset\n",
    "        The dataset for validation\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    history\n",
    "        The training history\n",
    "    \"\"\"\n",
    "        \n",
    "    import os\n",
    "    import datetime\n",
    "    from tensorflow import keras\n",
    "\n",
    "    training_epochs = params.get(\"training_epochs\", 5)\n",
    "    training_logdir = params.get(\"training_logdir\", None)\n",
    "    \n",
    "    if training_logdir is None:\n",
    "        training_logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    \n",
    "    #tensorboard_callback = keras.callbacks.TensorBoard(training_logdir, histogram_freq=1)\n",
    "\n",
    "    history = model.fit(\n",
    "        dataset_train,\n",
    "        validation_data=dataset_val,\n",
    "        #callbacks=[tensorboard_callback],\n",
    "        epochs=training_epochs)\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "def plot_history(history, filename=None):\n",
    "    \"\"\"Plots or stores the history of an optimization run\n",
    "\n",
    "    Parameters: \n",
    "        history: history\n",
    "            The history to plot\n",
    "        filename: str\n",
    "            The path and name of the file to save the confusion matrix (will not be plotted to the screen if set)\n",
    "    \"\"\"\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "        \n",
    "    plt.title('Accuracy')\n",
    "    plt.plot(history.history['accuracy'], label='train')\n",
    "    plt.plot(history.history['val_accuracy'], label='test')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.title('Loss')\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='test')\n",
    "    plt.legend()\n",
    "    \n",
    "    if filename is not None:\n",
    "        plt.savefig(filename, dpi=300)\n",
    "    else: \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the training/test/validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264949 train examples\n",
      "66238 test examples\n",
      "449506 train examples\n",
      "112377 test examples\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = get_train_test_split(params, data)\n",
    "data_train = pd.concat([data_train, data_aug])\n",
    "data_train, data_val = get_train_test_split(params, data_train)\n",
    "\n",
    "dataset_train = dataframe_to_dataset(params, data_train)\n",
    "dataset_test = dataframe_to_dataset(params, data_test)\n",
    "dataset_val = dataframe_to_dataset(params, data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text_clean': <tf.Tensor: shape=(128,), dtype=string, numpy=\n",
      "array([b'ich empfehle dr. hinterkausen sehr ! er ist ein sehr kompetenter und freundlicher arzt . auch seine ruhige art vermittelt gro\\xc3\\x9fes vertrauen . bei so einem guten arzt macht es mir \\xc3\\xbcberhaupt nichts aus , wenn ich ohne termin in die vormittagssprechstunde gehe und warten muss . das praxisteam erlebe ich als sehr freundlich und bei bedarf hilfsbereit .',\n",
      "       b'herr kuppinger umgibt sich mit einer damenriege , die wohl nicht sonderlich gut auf ihn zu sprechen ist . es werden viel zu viele patienten angenommen und zum zwecke der gewinnmaximierung durchgeschleust . der doktor nimmt sich nur sekunden ! ! f\\xc3\\xbcr diagn ose , angestrebte behandlung usw . dabei ge schehen fehler , die er einfach wegleugnet . ver trauen bei mir gleich null . ihm w\\xc3\\xa4re zu raten seine berufsauffassung zu \\xc3\\xbcberdenken oder weniger personal zu besch\\xc3\\xa4ftigen . die welt wird er so nicht retten k\\xc3\\xb6nnen',\n",
      "       b'kann jedem nur abraten diese praxis zu betreten . keinerlei kompetenz vorhanden . hier wird lotto mit der gesundheit des patienten gespielt .',\n",
      "       b'herr roser ist an unh\\xc3\\xb6flichkeit gar nicht zu toppen . er f\\xc3\\xa4hrt dem patienten \\xc3\\xbcber den mund ... wirkt von oben herab . nicht empfehlenswert !',\n",
      "       b'aus der erfahrung von kindern und verschiedenen \\xc3\\xa4rzten halte ich diesen arzt , vor allem nach seiner fehldiagnose diesmal und seinem v\\xc3\\xb6llig fehlendem einf\\xc3\\xbchlungsverm\\xc3\\xb6gen f\\xc3\\xbcr absolut ungeeignet . er ist hektisch bei den untersuchungen gegen\\xc3\\xbcber den kindern , fragen zu stellen unm\\xc3\\xb6glich , ist voreingenommen und aufgrund dieser punkte hat er jetzt eine gravierende fehldiagnose gestellt . halte ihn f\\xc3\\xbcr inkompetent und zu sehr von sich eingenommen . zudem bei starkem andrang zu hektisch und scheint \\xc3\\xbcberfordert . werde diesen arzt nicht wieder aufsuchen ! !',\n",
      "       b'man f\\xc3\\xbchlt sich toll aufgehoben bei dr. weber . er h\\xc3\\xb6rt zu , geht auf die individuelle problemlage ein . ein mann mit weitblick , der meiner erfahrung nach auch ausserhalb des medizinischen kastens denkt .',\n",
      "       b'ich wurde nichtmal gefragt warum ich da bin ... es ging nur um irgendwelche untersuchungen , die bezahlt werden m\\xc3\\xbcssen . die untersuchung die keine wahr , dauerte exakt min . ich habe monate auf diesen termin gewartet . aber die schwestern sind sehr nett .',\n",
      "       b'sehr nette schwestern . dr. gr\\xc3\\xbcber wirkt arrogant und gleichg\\xc3\\xbcltig zu meinem anliegen . reaktion auf meine beschwerden kenne ich , kenne ich . na toll ! ! ! gespr\\xc3\\xa4chsdauer zum problem wenigstens wurde medikamente verschrieben .',\n",
      "       b'ich hatte vor der meniskusarthroskopie nur lange zeit probleme beim joggen und so entschied ich mich f\\xc3\\xbcr die chirurgie . nach der operation wurde mir gesagt , dass es sehr erfolgreich sei . es sei nur der meniskus , knorpel und b\\xc3\\xa4nder seien in ordnung . nur leider wurde mein knie nach wochenlanger kleinerer zerrung dick und schmerzhaft . vom ersten tag nach der operation an hatte ich das gef\\xc3\\xbchl , dass etwas mit meinem knie nicht in ordnung war , und ich erz\\xc3\\xa4hlte dem arzt mehrmals davon . nur leider braucht herr damaschke nur vor einer operation zeit , nach der operation sieht man ihn nur noch laufen . er sagte mir mehrmals , er k\\xc3\\xb6nne mir nicht sagen , was falsch sei , aber es sei nicht normal . abgesehen von der physiotherapie sagt er nichts hierzu . in meiner verzweiflung wechselte ich den arzt nach mehreren besuchen , bei denen sofort ein neuer schmutz gespendet . jetzt habe ich eine weitere operation mit',\n",
      "       b'seit ich das zweite mal nach meinem zahnarztwechsel bei dr. mielke war , f\\xc3\\xbchle ich mich um meine zahngesundheit und betreung bestens versorgt . dr. mielke versteht es das fachliche in einen angenehmen gespr\\xc3\\xa4chsrahmen einzubetten . ein dickes lob gebe ich au\\xc3\\x9ferdem f\\xc3\\xbcr die ungew\\xc3\\xb6hnlich aber sehr angenehme kurze wartezeit durch ein gut abgestimmtes terminbelegungssystem . keine behandlung dauerte l\\xc3\\xa4nger als eine halbe stunde inkl . wartezeit .',\n",
      "       b'ziemlich guter arzt , k\\xc3\\xb6nnte aber ein bisschen freundlicher sein',\n",
      "       b'ich hatte problem mit einem auge , hatte jeden morgen schleim , konnte sogar nicht aufmachen . frau doktor meinte , dass meine augen obwohl ich hatte problem nur mit einem nur trocken sind . ich habe von ihr feuchtigkeitsaugentropfen aus dem schrank gekriegt . au\\xc3\\x9ferdem hat sie mir vom fu\\xc3\\x9f bis kopf angeschaut , als ich reingekommen bin . ich hatte so ein gef\\xc3\\xbchl , dass ich eine bewertung bekommen muss , bevor ich ihre kompetente oder nicht kompetente hilfe kriege !',\n",
      "       b'meiner meinung nach sollte man diese praxis meiden . ich pers\\xc3\\xb6nlich hatte sehr schlechte erfahrung mit der kompetenz der \\xc3\\xa4rztin . sie scheint mir sehr unerfahren und gibt desweiteren fehlinformationen . diese kostet dem kunden nat\\xc3\\xbcrlich zeit . weist man die \\xc3\\xa4rztin auf ihre fehler hin , wird sehr unh\\xc3\\xb6flich reagiert , was in meinen augen nicht die bevorzugte art ist . ich h\\xc3\\xa4tte gerne eine bessere bewertung abgegeben , aber hier hatte ich eine meiner schlechtesten erfahrung mit \\xc3\\xa4rzten . wem seine z\\xc3\\xa4hne und sein geld lieb sind , sollte , meiner meinung nach , einen anderen zahnarzt aufsuchen . auch sollte man sich nicht vom ersten eindruck der \\xc3\\xa4rztin t\\xc3\\xa4uschen lassen dieser scheint nat\\xc3\\xbcrlich sehr nett doch \\xc3\\xa4ndert er sich sobald man anmerkungen hat , die ihr pers\\xc3\\xb6nlich nicht passen .',\n",
      "       b'die qualit\\xc3\\xa4t der praxis hat sehr nachgelassen . unheimlich lange wartezeiten auf termine sowie wartezeiten in der praxis . man muss mindestens eine stunde mit verz\\xc3\\xb6gerung rechnen !',\n",
      "       b'super artzt ich w\\xc3\\xbcrde empfehlen einen patientenstopp zu machen da es sehr \\xc3\\xbcberf\\xc3\\xbcllt ist',\n",
      "       b'ich habe mich nicht ernst genommen gef\\xc3\\xbchlt , wunsch nach anderen behandlungsm\\xc3\\xb6glichkeiten wurde mit augen verdrehen kommentiert . detailreiche informationen zu meiner verletzung habe ich auch nicht bekommen . nachdem mein verband nach einem kontrolltermin zu fest sa\\xc3\\x9f und ich taubheitsgef\\xc3\\xbchle hatte wurde ich weggeschickt mit der aussage das sind muskeldchmerzen , das ist normal jetzt bin ich zum gl\\xc3\\xbcck bei einem anderen arzt , bei dem ich mich sehr wohlf\\xc3\\xbchle .',\n",
      "       b'ich gehe nicht sehr oft zum arzt , vllt . bis mal im jahr . allerdings geht es mir dann wirklich schlecht , wenn ich doch zum arzt gehe . bei meinen letzten besuchen , die insgesamt ca . jahre an zeitraum umfassen , hatte ich jedes mal das gef\\xc3\\xbchl , dr. l\\xc3\\xb6hrer n\\xc3\\xa4hm meine beschwerden nicht ernst und wollte l\\xc3\\xa4ssig und cool auf mich wirken . ein mittelchen hier , damit ist einem gerade in solchen situationen nicht geholfen . hinzukommt , dass die kommunikation mit ihm manchmal sehr schwer ist ! sehr oft muss man sich wiederholen .',\n",
      "       b'sehr freundliches personal . tolle betreuung vom arzt und dem team . gute aufkl\\xc3\\xa4rung . fragen werden immer beantworten . die angst vor dem zahnarzt wird einem genommen . bis jetzt rundum zufrieden .',\n",
      "       b'unqualifizierte behandlung und anschlie\\xc3\\x9fender erhalt einer enormen rechnung',\n",
      "       b'als herr dr. wessendorf sagte , ich solle mich entscheiden , ob ich meinen gebrochenen zeh oder meine massiven r\\xc3\\xbcckenschmerzen bei diesem termin behandeln m\\xc3\\xb6chte , weil ich nur eines tun w\\xc3\\xbcrde , dachte ich , dass es zuerst ein scherz ist . ich fragte mehrmals nach , aber es war kein witze . er erkl\\xc3\\xa4rte kurz , dass der behandlungserfolg geringer w\\xc3\\xa4re , wenn er beides bei einem termin behandeln m\\xc3\\xbcsste . ich dachte daran , geradeaus zur\\xc3\\xbcckzugehen , aber ich hatte trotz des termins bereits gewartet und zudem unter beeintr\\xc3\\xa4chtigungen gelitten . ich entschied mich f\\xc3\\xbcr den zeh , durfte noch eine minute auf das r\\xc3\\xb6ntgen warten und dann zur\\xc3\\xbcck in den behandlungsraum mit tja , man kann nichts tun , um willkommen gehei\\xc3\\x9fen zu werden . als er gefragt wurde , dass der zeh gebrochen sei , hatte ich es ihm bereits gesagt und er w\\xc3\\xbcrde ihm trotzen . er fragte auch , warum ich mir offenbar wieder den zeh gebrochen habe',\n",
      "       b'ich schlie\\xc3\\x9fe mich dem vorkommentator an ! zudem unverst\\xc3\\xa4ndliche diagnosen !',\n",
      "       b'ich fand das wartezimmer zu klein und beengt , au\\xc3\\x9ferdem befindet es sich direkt neben dem empfangsbereich . das hei\\xc3\\x9ft , man kann nicht in ruhe warten sondern wird st\\xc3\\xa4ndig durch ankommende anrufe oder sonstige gespr\\xc3\\xa4che der sprechstundenhilfe gest\\xc3\\xb6rt . au\\xc3\\x9ferdem musste ich trotz termin minuten warten bis ich dran war . die \\xc3\\xa4rztin ist allerdings sehr nett und kompetent , sodass sich das warten gelohnt hat .',\n",
      "       b'von den , stunden , die ich dort trotz termin verbracht habe , war der arzt insgesamt zweimal im zimmer und die gespr\\xc3\\xa4chszeit betrug gro\\xc3\\x9fz\\xc3\\xbcgig gerechnet min . wobei man hinzuf\\xc3\\xbcgen mu\\xc3\\x9f , dass er beim zweiten mal die r\\xc3\\xb6ntgenbilder mit mir besprechen wollte und mich aber eigentlich nur h\\xc3\\xb6flich zur t\\xc3\\xbcr begleitet hat . also diesen arzt kann man nicht ernsthaft guten gewissens weiterempfehlen !',\n",
      "       b'es fehlt im wartezimmer die m\\xc3\\xb6glichkeit sich in ruhe umzuziehen',\n",
      "       b'kann ich nur empfehlen , wenn man hart im nehmen ist !',\n",
      "       b'es f\\xc3\\xa4ngt schon beim empfang an das man unfreundlich behandelt wird . frau eversmeyer hat mein krenkheitsbild nicht ernst genommen und als ich sie auf meine unvertr\\xc3\\xa4gliche reaktion von einem antibiotika erz\\xc3\\xa4hlte die sie mir aufschreiben wollte wurde sie laut und was das soll sie weiss nicht was sie mit mir machen sollte ich usw . ich werde nie mehr wieder zu diese praxis gehen .',\n",
      "       b'nicht durch pl\\xc3\\xb6tzliche schmerzen im bein empfohlen werden , begann er mit einer verstauchung und schickte mich nach hause am ende war es eine thrombose , die t\\xc3\\xb6dlich h\\xc3\\xa4tte sein k\\xc3\\xb6nnen , gott sei dank suchte ich einen anderen arzt , der alles richtig machte ! !',\n",
      "       b'keine richtige diagnose , keine behandlung der ursache , stattdessen wurden mir euro-pflegeprodukte aus meinem eigenen laden im vorraum verschrieben . nie wieder !',\n",
      "       b'ich war zwei mal bei diesem arzt und habe mich beide male nicht wirklich wohl gef\\xc3\\xbchlt . ich war beide male nicht l\\xc3\\xa4nge als minuten in behandlung . meine haut hat er \\xc3\\xbcberhaupt nicht gr\\xc3\\xbcndlich untersucht und daraufhin irgendeine creme rezeptiert . ohne mir \\xc3\\xbcberhaupt zu erkl\\xc3\\xa4ren , was ich habe . nach wochen hatte ich immer noch probleme bzw . verschlimmerte hautver\\xc3\\xa4nderungen . daraufhin hat er eine diagnose gestellt , die absolut nicht stimmen konnte . hauptsache schnell behandeln und weiter . schade ! !',\n",
      "       b'dr. airanow hat einen b\\xc3\\xa4nderriss zu sp\\xc3\\xa4t erkannt und nicht behandelt er gab dieses fehlverhalten sogar zu oh , warum haben wir denn keine schiene gelegt wie konnte das passieren ? und als ich ihn fragte , was ich nun noch machen kann , war seine lapidare antwort blo\\xc3\\x9f jetzt kann man nichts mehr machen , f\\xc3\\xbcr eine schiene ist es zu sp\\xc3\\xa4t fallen sie einfach nicht mehr . dann verlie\\xc3\\x9f er das behandlungszimmer und ich blieb sprachlos zur\\xc3\\xbcck ...',\n",
      "       b'seit bei fr . dick und alles was ich hier gelesen habe trifft auch auf mich zu ! mit als kind betitelt schmerzende krebs op narben werden mit magnesium und vaginalflora tabl behandelt vitamin hilft f\\xc3\\xbcr und gegen alles inneren einblutungen und postive krebstests werden nur beobachten wird man gyn not operiert , weil sie nichts getan hat , bekommt man nur noch \\xc3\\xbcberweisungen ins krankenhaus ohne behandlung in der schwangerschaft bis hat sich nichts ge\\xc3\\xa4ndert , bin weg',\n",
      "       b'ich war regelm\\xc3\\xa4\\xc3\\x9fig zur kontrolle in der praxis und trotz zu hohem blutdruck und wassereinlagerungen am ganzen k\\xc3\\xb6rper , worauf ich hingewiesen habe wurde ich ohne entsprechende behandlung oder aufkl\\xc3\\xa4rung wieder nach hause geschickt . das hat meiner kleinen und mir fast das leben gekostet . sie wurde per notkeiserschnitt im letzten moment auf die welt geholt und musste beatmet werden . und frau dr. hat w\\xc3\\xa4hrend der ganzen schwangerschaft gesagt es wird ein junge . wir haben aber ein m\\xc3\\xa4dchen bekommen und waren alle sehr \\xc3\\xbcberrascht . also f\\xc3\\xbcr schwangere keine gute \\xc3\\xa4rztin ! ! ! gef\\xc3\\xa4hrlich !',\n",
      "       b'sehr freundlicher und perfektionistischer zahntechniker und zahnarzt . kann ich nur empfehlen ...',\n",
      "       b'selten eine so unangenehme art bei einem arzt erlebt .',\n",
      "       b'aufgrund von auff\\xc3\\xa4lligkeiten in den nierenwerten suchte ich frau dr milsman auf . es war nach einiger zeit mein .besuch bei ihr . auch diesmal wurde ich von den arzthelferinnen freundlich betreut und frau dr milsman nahm sich auch wieder viel zeit f\\xc3\\xbcr das vorgespr\\xc3\\xa4ch und konnte mich dadurch erstmal wegen meiner \\xc3\\xa4ngste beruhigen . ich f\\xc3\\xbchle mich bei der \\xc3\\xa4rztin gut aufgehoben und kann sie aus meinen bisherigen erfahrungen nur weiter empfehlen .',\n",
      "       b'seit jahren bin ich patient von der praxis m\\xc3\\xbcller kresse . au\\xc3\\x9fer wartezeiten von \\xc3\\xbcber stunde mit termin hatte ich bisher nichts zu bem\\xc3\\xa4ngeln . nun ben\\xc3\\xb6tigte ich jetzt einen termin wegen problemen mit den augen . die praxis war nicht bereit mir einen termin zu geben . erst in monaten k\\xc3\\xb6nne ich einen termin bekommen . es wurde mir dann gesagt , wenn es sich um einen notfall handelt , soll ich in ein krankenhaus gehen , oder mir einen anderen arzt suchen , ich habe dann einen anderen arzt gefunden und am n\\xc3\\xa4chsten tag einen untersuchungstermin bekommen . ich werde bestimmt nicht mehr die praxis m\\xc3\\xbcller kresse aufsuchen und auch nicht empfehlen .',\n",
      "       b'ich wurde von mr. prof. schlegel bei einer weisheitszahnentfernung am nerv verletzt und habe seitdem ein taubes kinn und eine taube unterlippe , v\\xc3\\xb6lliger empfindlichkeitsverlust . ich war sehr schlecht und unzureichend aufgekl\\xc3\\xa4rt , mr. prof. schlegel nahm sich kaum zeit . er riet mir zu einer vollnarkose , was leider das risiko erh\\xc3\\xb6hte . au\\xc3\\x9ferdem w\\xc3\\xa4re unmittelbar danach eine anti\\xc3\\xb6dematosetherapie notwendig . ich wollte mich am tag der operation informieren , bekam ihn aber nicht mehr zu sehen , wurde sofort bet\\xc3\\xa4ubt . das risiko einer nervenverletzung war , wie ich heute wei\\xc3\\x9f , extrem hoch . es ging von au\\xc3\\x9fen schief . das r\\xc3\\xb6ntgen wurde nicht gerettet , also wurde ich unn\\xc3\\xb6tig ein zweites mal ger\\xc3\\xb6ntgt . ich kann nur jedem raten , sich eine zweite meinung zu bekommen . ich sollte es niemals tun .',\n",
      "       b'auf der suche nach einem guten arzt bin ich durch die vielen positiven bewertungen so zu diesem arzt gekommen . nach dieser erfahrung , werde ich von zu positiv bewerteten \\xc3\\xa4rzten abstand nehmen . ich habe kein vertrauen zu diesem arzt . vielmehr hatte ich das gef\\xc3\\xbchl dass dr. dubiel einem eine kostspielige und riskante behandlung einreden wollte , die nicht zwingend erforderlich ist . ich war sehr erschrocken \\xc3\\xbcber die vorgehensweise dieses arztes und gleichzeitig traurig , dass es hier offensichtlich ums geldmachen geht als um das wohl des patienten . bitte passt auf und lasst euch immer eine zweit und drittmeinung geben bevor ihr eine op oder eine behandlung eingeht ! !',\n",
      "       b'bin bei dr. metz schon seit vielen jahren , und habe mich immer gut aufgehoben gef\\xc3\\xbchlt .',\n",
      "       b'hallo , ich musste einmal die pille danach nehmen , anstatt natalia . mir die geben sollte , hat sie erstmal mich im wartezimmer genau std warten lassen ! ! obwohl die genau wussten dass ich die pille danach gebraucht habe . die pille danach sollte man schnell wie m\\xc3\\xb6glich einnehmen wegen der wirkung anstatt sie mir das aush\\xc3\\xa4ndigen sollte hat sie im flur mit mir diskutiert hab sie aufgegriffen dass sie es nicht geben muss wegen meinem zyklus . logischerweise ist es immer ein risiko ! ! ! ein zyklus kann sich immer verschieben also unsinn bin dann zu einem anderen arzt gegangen hab es auch sofort dort bekommen , will ja kein kind mit meinen jahren kriegen . ! ! ! richtig geizig was medikamente angeht ! ! w\\xc3\\xbcrde lieber woanders hingehen ! !',\n",
      "       b'keine langen wartezeiten , tolles behandlungsergebnis , nettes praxisteam bin sehr zufrieden !',\n",
      "       b'nach einer kleinen odysee hoffe ich jetzt den richtigen zahnarzt gefunden zu haben .',\n",
      "       b'mein sohn hat viele kleine problene wir haben krankengymnastik verschrieben bekommen da war er ca monate ohne proble jetzt ist er jahre und bekommt logop\\xc3\\xa4die und ergotherapie ohne probleme sie nimmt sich zeit und schaut genau sie hat ein gutes gef\\xc3\\xbchl was kinder brauchen und was nicht ! und das w\\xc3\\xbcnsche ich mir von einer \\xc3\\xa4rztin ! ! ! sie hat mir sogar den vorschlag gemacht zum osteopathen zu gehn . den muss ich aber privat bezahlen und das war genau richtig f\\xc3\\xbcr uns . der osteopath konnte uns super unterst\\xc3\\xbctzen . und die stempel bescheinigungen usw muss sie geld nehmen das ist von der krankenkasse so vorgeschrieben . und an alle eltern seit froh das sie nicht so viele medikamente aufschreibt oder wollt ihr alle die kinder damit voll stopfen es geht auch mit pflanzlichen oder hom\\xc3\\xb6opathischen mitteln die sind auch schonender . au\\xc3\\x9ferdem hat jeder mal einen schlechten tag \\xc3\\xa4rzte und arzthelfer sind auch nur menschen und machen auch mal kleine fehler und sind nicht immer gut gelaunt da sollten wir alle nicht so streng sein ! ! ! das einzige minus ist das man schwer einen parkplatz bekommt \\xc3\\xb6ffentliche verkehrsm\\xc3\\xb6glichkeiten sind gut und das die praxis im .stock ist und f\\xc3\\xbcr kinderw\\xc3\\xa4gen wenig platz ist .',\n",
      "       b'ich dachte endlich in richtigen h\\xc3\\xa4nden zu sein aber nach der op am knie knorpel gl\\xc3\\xa4ttung und miniskus bin ich heute noch mit gehstutzen es sind jetzt genau wochen und ich kann immer noch nicht strecken und gehen knie immer noch dick noch schlimmer ist aber das er mich nicht mehr weiter behandeln m\\xc3\\xb6chte und mir die arzthelferinnen sagten das dr strauss nichts mehr f\\xc3\\xbcr mich tun kann ich sollte mir einen ortopathen suchen der konsevativ behandelt . ich habe mich als ter klasse gef\\xc3\\xbchlt .',\n",
      "       b'tolle praxis ! schwester gisela und schwester bea sind echt ein tolles team . sind erst bei einem anderen arzt , meine tochter und ich waren dort nicht sehr gl\\xc3\\xbccklich . seid wir in dieser praxis sind und von fr . dr. kr\\xc3\\xb6ber betreut werden f\\xc3\\xbchlen wir uns rundum wohl , gut betreut und beraten auch wenn es mal l\\xc3\\xa4nger dauert . danke',\n",
      "       b'dr. rabinovich nimmt sich zeit f\\xc3\\xbcr den patienten . sehr zu empfehlen ist die computergesteuerte narkose habe fr\\xc3\\xbcher immer tagelang schmerzen von der einstichnadel gehabt in dieser praxis absolut angenehm und schmerzfrei . toll sind auch die gemachten fotos anhand er die weitere behandlung erkl\\xc3\\xa4rt und nebenbei kann man es auch sichtbar nachvollziehen . in der regel bekommt man schnell einen termin .',\n",
      "       b'bin seit mehrern jahren bei herren .dr mahdavi und immer sehr happy und hochzufrieden mit seinem leistung . ich f\\xc3\\xbchle mich bei ihm bestens aufgehoben und dass ich in guten h\\xc3\\xa4nde bin . er ist mit herz und verstand dabei und ich vertraue ihn sehr . ich m\\xc3\\xb6chte mich ganz herzlich bei den ganzemteam bedanken . die professionelle zahnreinigung ist in der praxis hervorragend . alles top . herren dr .mahdavi ist a\\xc3\\xbc\\xc3\\x9ferst empfehlenswert .',\n",
      "       b'wie oben schon geschrieben ist bei dieser frauen\\xc3\\xa4rztin alles ziemlich alt . warten tun sie leider trotz termin auch mal und wenn man heutzutage keine mit hat , darf man noch nicht einmal \\xc3\\xbcberweisen . fr\\xc3\\xbcher ging das . das anmeldungspersonal sehr unfreundlich und geht nie ans telefon ach doch vllt . mal in einer stunde deswegen muss man auch einen termin vor ort machen wenn man einen m\\xc3\\xb6chte . ich w\\xc3\\xbcrde euch allen diese \\xc3\\xa4rztin nicht weiterempfehlen .',\n",
      "       b'ich kann die schlechten bewertungen nur best\\xc3\\xa4tigen . ich war einmal auf empfehlung bei fr . lais und nie wieder ! damals war ich schwanger und in einer verzweifelten situation . sie hat mich wissen lassen das es sie nicht interessiert und ich mich nicht so anstellen soll ! wohl gemerkt ich bin eine kollegin aus dem klinikbereich und bin eigentlich nicht sehr zimperlich ! nie wieder ! ! ! ! !',\n",
      "       b'diese \\xc3\\xa4rztin geht gar nicht . sie hat einfach kein gesp\\xc3\\xbcr f\\xc3\\xbcr kranke kinder . ist sehr ruppig und hat keine geduld . meine tochter ist fr\\xc3\\xbcher gerne zum arzt gegangen und sie hat es komplett versaut . vielen dank frau dr. martinez . alternativmedizin scheint auch nicht ihre st\\xc3\\xa4rke zu sein . auf fragen diesbez\\xc3\\xbcglich weicht sie immer aus .',\n",
      "       b'sehr schlechte erfahrung',\n",
      "       b'die kooperation mit anderen fach\\xc3\\xa4rzten klappt hervorragend . sehr zu empfehlen .',\n",
      "       b'geht sehr gut auf den patienten ein und nimmt ihm jede scheu scheut sich auch nicht eine behandlung abzubrechen wenn er merkt das der patient noch schmerzen empfindet und schiebt ihn wieder zwischendurch ein auch ohne termin . fachlich aus meiner sicht sehr gut und super schnell meine behandlung war nach ca min . abgeschlossen obwohl z\\xc3\\xa4hne gemacht werden mussten , und ich hatte auch keine probleme danach .',\n",
      "       b'sowas darf doch kein arzt werden geht gar net ! ! !',\n",
      "       b'dr r\\xc3\\xb6del ist leider ziemlich inkompetent . er hatte bei mir eine diagnose gestellt die \\xc3\\xbcberhaupt nicht stimmte ... ich wurde eine gewisse zeit mit medikamenten vollgepumpt die ich nich gebraucht und ben\\xc3\\xb6tigt h\\xc3\\xa4tte . gott sei dank hat sich bei meiner neuen \\xc3\\xa4rztin alles noch aufgekl\\xc3\\xa4rt aber da soviel zeit vergangen ist , ist es nat\\xc3\\xbcrlich jetzt arg schlimm geworden . wer eine korrekte diagnose will und nicht gleich als psychisch krank hingestellt werden will geht lieber woanders hin .',\n",
      "       b'super nette und kompetente \\xc3\\xa4rztin . auch das praxispersonal ist sehr freundlich und hilfsbereit .',\n",
      "       b'mit r\\xc3\\xbcckenschmerzen , ist man leider bei dieser \\xc3\\xa4rztin fehl am platz !',\n",
      "       b'super unfreundliches personal inkl . \\xc3\\xa4rztin . stunden wartezeit , und die privatpatienten marschieren an einem vorbei ins behandlungszimmer . notfall patientin wurde r\\xc3\\xbcde der praxis verwiesen w\\xc3\\xa4hrend ich wartete man h\\xc3\\xa4tte keine zeit und das junge m\\xc3\\xa4dchen mit freundinnen sollte doch ins krankenhaus gehen mit ihrem zugeschwollenem auge . mein gr\\xc3\\xbcner star wurde nicht erkannt , und mir wurde eine kopie meiner krankenakte verweigert . meine derzeitige \\xc3\\xa4rztin hat mit m\\xc3\\xbche und not teile der diagnose erhalten . diese \\xc3\\xa4rztin samt personal ist eine absolute katastrophe und sollte ihre zulassung zur\\xc3\\xbcck geben ! ich kann leider die hier aufgef\\xc3\\xbchrten negativen bewertungen nur best\\xc3\\xa4tigen',\n",
      "       b'ich kann frau dr. friedel sehr empfehlen . einen termin konnte ich ohne gro\\xc3\\x9fe wartezeiten vereinbaren . bin p\\xc3\\xbcnktlich zum termin dran gekommen . die \\xc3\\xa4rztin hat sich viel zeit genommen und alles wurde ausf\\xc3\\xbchrlich besprochen und erkl\\xc3\\xa4rt .',\n",
      "       b'meine erfahrungen mit dr. tourbier und dem team sind sehr durchwachsen . das team wirkte schon immer sehr gestresst , \\xc3\\xbcberfordert und in folge dessen unfreundlich bis teilweise pampig . vermutlich ist dies abh\\xc3\\xa4ngig von dem volumen an patienten und arbeit , das es zu bew\\xc3\\xa4ltigen gilt . dennoch ist dies nicht damit zu rechtfertigen . bei einem eitrigen fu\\xc3\\x9fnagel meines sohnes in meinen augen ein notfall verwies mich die sprechstundenhilfe auf einen dermatologen in der n\\xc3\\xa4he meines wohnortes . man sei aktuell \\xc3\\xbcberf\\xc3\\xbcllt und k\\xc3\\xb6nne deshalb meinen sohn nicht behandeln . und das obwohl sowohl mein sohn als auch ich zu der zeit bereits patienten waren . als ich ein anderes mal meinen termin nicht mehr wusste mein terminkalender ging verloren und dort anrief um diesen zu erfragen war die reaktion der sprechstundenhilfe sehr unfreundlich und absolut nicht hilfsbereit . man sagte mir , ich m\\xc3\\xbcsse einen neuen termin vereinbaren , welcher ca mit sechs monaten wartezeit verbunden sei . die begr\\xc3\\xbcndung daf\\xc3\\xbcr sei , dass man nach kurzem bl\\xc3\\xa4ttern durch das terminbuch meinen termin nicht finden konnte und keine zeit f\\xc3\\xbcr solche dinge h\\xc3\\xa4tte . als kurze zeit sp\\xc3\\xa4ter mein mann in der praxis anrief und sich nicht abwimmeln lie\\xc3\\x9f , wurde er mit der gleichen unfreundlichkeit behandelt , wie ich kurz davor . allerdings schaffte er es den termin zu erfahren , welcher nur sechs wochentage nach unserem anruf lag . ich frage mich ernsthaft , wie die sprechstundenhilfe bei meinem anruf bei dem durchbl\\xc3\\xa4ttern des terminbuches meinen termin nicht finden konnte ? ! bei meinem termin selbst behandelte mich der arzt in der schon mehrfach beschriebenen eile . nach der behandlung , welche weniger als drei minuten dauerte , legte mir der arzt nahe einen dermatologen nahe meines wohnortes zu konsultieren . man behandele keine patienten aus umliegenden st\\xc3\\xa4dten . schon gar nicht wenn es laut der sprechstundenhilfe solche probleme mit den patienten g\\xc3\\xa4be .',\n",
      "       b'frau schlee l\\xc3\\xa4sst sich keine zeit , v\\xc3\\xb6llig gleichg\\xc3\\xbcltig zu sein .',\n",
      "       b'die wartezeit war okay , die frauen an der rezeption unglaublich unfreundlich ! ! der arzt hat sich keine zeit genommen und schien auch nicht sehr interessiert . er ist nicht mal mit in ein zimmer gekommen er hat mir schnell an der rezeption lediglich ein antibiotikum verschrieben , obwohl er der meinung ist , dass ich ausschlie\\xc3\\x9flich nebenwirkungen davon bek\\xc3\\xa4me ! ! ich konnte nichtmal aussprechen um ihm mein befinden zu erkl\\xc3\\xa4ren . es hat ihn einfach nicht interessiert also wirklich schrecklich .',\n",
      "       b'unflexibel , lange wartezeiten , unh\\xc3\\xb6fliches personal , mangelndes vertrauensgef\\xc3\\xbchl zur \\xc3\\xa4rtzin',\n",
      "       b'wir gehen seit etwa jahren zu frau dr. zagrean und k\\xc3\\xb6nnen uns keine andere zahn\\xc3\\xa4rztin f\\xc3\\xbcr unsere kinder vorstellen . sie ist sehr freundlich , kompetent und hat uns noch nie einen falschen rat gegeben . unsere kinder gehen sehr gerne zum zahnarzt , was sicher nicht immer \\xc3\\xbcblich ist',\n",
      "       b'dieser arzt hat mir ultraschall verweigert weil ich die . euro f\\xc3\\xbcr igel leistung als harz empf\\xc3\\xa4ngerin nicht hatte . ohne beschwerden m\\xc3\\xbcsste man es selber zahlen . ich antwortete wahrheitsgem\\xc3\\xa4ss , dass ich keine schmerzen habe und wurde nicht untersucht . jetzt musste meine geb\\xc3\\xa4rmutter entfernt werden , ich habe keine kinder weil in der zwischenzeit wucherten einige myome dort . die machen auch keine beschwerden . na ja immerhin so verhindert man das noch mehr hartz empf\\xc3\\xa4nger auf die welt kommen . was f\\xc3\\xbcr eine d\\xc3\\xa4mliche logik ist das wenn einige krankheitsbilder keine symptome verursachen und myome ab nun mal keine seltenheit sind ?',\n",
      "       b'meine erfahrung bei dr. levy pers\\xc3\\xb6nnlichkeit total unfreundlich , herablassend , menschenfeindlich . kompetenz er spricht franz\\xc3\\xb6sisch , was f\\xc3\\xbcr mich einfacher war . verschreibung er verschrieb mir ein mittel gegen ekzeme und hautjucken nach tagen keine wirkung . ich bin heute bei einem anderen hautarzt gewesen , was ich ihnen empfehle wenn sie die m\\xc3\\xb6glichkeit haben . schade dass es so wenig haut\\xc3\\xa4rzte in berlin sind .',\n",
      "       b'doktor titze nimmt sich zeit trotz hoher auslastung und hat f\\xc3\\xbcr alles ein offenes ohr , ein arzt mit leib und seele man merkt das er seinen beruf nicht macht um geld zu verdienen , sondern um menschen zu helfen ! ! ! ! ich bin sehr dankbar das wir ihn als hausarzt an unserer seite haben und das gilt f\\xc3\\xbcr die ganze familie ! ! ! ! !',\n",
      "       b'ich habe mich bei dr. dannhof sehr gut aufgehoben gef\\xc3\\xbchlt . einen termin bei ihm zu kriegen war allerdings nicht immer ganz einfach . kann ihn uneingeschr\\xc3\\xa4nkt weiterempfehlen .',\n",
      "       b'professionell , kompetent , einf\\xc3\\xbchlsam , zugewandt , freundlich und von grund auf positiv eingestellt von dieser praxis kann ich nur schw\\xc3\\xa4rmen ! jederzeit habe ich mich bei frau dr. halis und auch den anderen \\xc3\\xa4rztinnen gut aufgehoben und beraten gef\\xc3\\xbchlt . leider ist das nicht selbstverst\\xc3\\xa4ndlich , wie ich nach der erfahrung in einer anderen praxis erleben musste . zwischenmenschliche w\\xc3\\xa4rme und das gef\\xc3\\xbchl , nicht in einer massenabfertigung zu stecken , sind mir eben doch sehr wichtig . aus meiner sicht ist diese klinik daher die beste wahl , die man treffen kann . jederzeit w\\xc3\\xbcrde ich sie uneingeschr\\xc3\\xa4nkt jedem empfehlen . die hier schon \\xc3\\xb6fter erw\\xc3\\xa4hnten l\\xc3\\xa4ngeren wartezeiten , auch am telefon , kann ich best\\xc3\\xa4tigen . darauf kann man sich aber einstellen und sie werden durch die vielen positiven aspekte mehr als wettgemacht .',\n",
      "       b'ich war sehr ern\\xc3\\xbcchtert , da weder die terminvereinbarung , noch die untersuchung an sich angenehm war . aber es war ok. zur kr\\xc3\\xb6nung wurde ich bei der . untersuchung war eine neue patientin zu dem zeitpunkt , einfach an eine andere \\xc3\\xa4rztin \\xc3\\xbcbergeben , ohne dass nur ein wort dazu gesagt wurde , wieso ich pl\\xc3\\xb6tzlich nicht mehr bei meiner \\xc3\\xa4rztin bin . schlie\\xc3\\x9flich kam ich extra wegen frau dr. mergard in die praxis . auch die betreuung im anschluss lie\\xc3\\x9f enorm zu w\\xc3\\xbcnschen \\xc3\\xbcbrig .',\n",
      "       b'seit jahren bin ich immer wieder bei dr. wessmann in behandlung , habe von allergien bis zu kleinen ops viele themen gehabt . immer hat er freundlich , kompetent und flott reagiert und mich von mancherlei beschwerden und problemen befreit . sein humor hat auch unangenehme momente . bei einer laserbehandlung \\xc3\\xbcberbr\\xc3\\xbcckt .',\n",
      "       b'diese \\xc3\\xa4rztin kann ich niemanden weiter empfehlen .',\n",
      "       b'herr steinbach ist ein sehr sorgf\\xc3\\xa4ltiger arzt , der sich sehr bem\\xc3\\xbcht die erkrankung eines patienten umfassend zu erfassen und den patienten als ganzes nicht aus den augen verliert. , er nimmt die anregungen der patienten auf , \\xc3\\xbcberdenkt sie und integriert sie , wenn aus medizinischer sicht m\\xc3\\xb6glich in sein therapiekonzept . das praxisteam ist freundlich und vermittelt einem fast eine freudschaftliche famili\\xc3\\xa4re atmosph\\xc3\\xa4re . formale dinge wie das abholen von rezepten verlaufen schnell und reibungslos . also insgesamt bin ich sehr zufrieden',\n",
      "       b'meine frau war bereits mit einer \\xc3\\xa4u\\xc3\\x9ferst komplizierten zahnbehandlung bei frau . als ich selbst nach langer zeit einen neuen zahnarzt suchte , empfahl sie mir uneingeschr\\xc3\\xa4nkt frau . bei mir selbst musste eine wurzelbehandlung sowie eine extraktion durchgef\\xc3\\xbchrt werden . bekanntlich recht unangenehme behandlungen . frau . hat beide behandlungen mit gr\\xc3\\xb6\\xc3\\x9fter sorgfalt schmerzfrei durchgef\\xc3\\xbchrt . dabei half sicherlich auch ihr \\xc3\\xa4u\\xc3\\x9ferst freundliches und entgegenkommendes verhalten .',\n",
      "       b'sehr moderne behandlungsmethoden , handwerklich sehr geschickt und vorsichtig . dabei ist er auch noch schnell und effektiv , ohne dass man den eindruck bekommt er w\\xc3\\xa4re ungenau . ein seh netter und sympathischer zahnarzt . ich hoffe er bleibt noch lange dabei .',\n",
      "       b'ich bin durch zufall von frau hasanli behandelt worden und wurde leider sehr entt\\xc3\\xa4uscht . sie machte durchgehend einen sehr gelangweilten , desinteressierten eindruck , hat sich mehr in den stuhl gepflegelt als darin zu sitzen . meine erkl\\xc3\\xa4rung von meinem beschwerden wurde mit einer handbewegung unterbrochen . nach minuten zeit beim arzt nach knapp stunden wartezeit hatte ich eine krankschreibung , aber keine ahnung , was mir fehlte . ich habe dann zus\\xc3\\xa4tzlich noch einen anderen arzt zu rate gezogen .',\n",
      "       b'dieser arzt war unh\\xc3\\xb6flich , desinteressiert , hat nicht wirklich zugeh\\xc3\\xb6rt , war herablassend und absch\\xc3\\xa4tzig . zudem hat er die symptome nicht erkannt bzw . die schilderung dieser nicht ernst genommen , und dann trotz starker beschwerden meinerseits sein urteil gesprochen gesund . nach diesem erlebnis war ich am selben tag noch bei einem anderen , kompetenten arzt , der eine eingehende diagnostik durchf\\xc3\\xbchrte hat zugeh\\xc3\\xb6rt und symptombeschreibung ernst genommen und die vorliegende erkrankung erkannte und fundiert behandelte . ich bin immer noch wirklich sprachlos \\xc3\\xbcber diese behandlung , so etwas habe ich zum gl\\xc3\\xbcck noch nie noch nicht einmal ansatzweise ! erlebt und werde es hoffentlich auch nie , nie wieder erleben . war wirklich eine katastrophe . klares urteil meinerseits keinesfalls zu empfehlen',\n",
      "       b'ich hatte eine magen-darm-koloskopie und eine anschlie\\xc3\\x9fende antibiotikatherapie bei frau keck . sie schien kompetent , nahm sich aber kaum zeit f\\xc3\\xbcr mich. generell kann ich die praxis nicht empfehlen , vor allem wegen der angestellten , die sehr unfreundlich , manchmal zickig , ignorant und v\\xc3\\xb6llig inkompetent sind , z . b. bei der blutentnahme und auch bei kleinen dingen wie dem termin . zum beispiel hatte ich bei der antibiotikaeinnahme schwarze r\\xc3\\xbcckst\\xc3\\xa4nde im speichel . sofort rief ich die praxis an , was mich nat\\xc3\\xbcrlich lange warten lie\\xc3\\x9fte . danach kam die antwort wahrscheinlich nicht von mir . recherchen bei einem apotheker ergaben noch etwas , was \\xc3\\xbcbrigens auch die behandlung der praxis mit ihren patienten sehr schlecht findet . wieder wurde mir der befund einer anderen patientin zugesandt , die dann wahrscheinlich auch meine befunde erhielt .',\n",
      "       b'lange wartezeit , ein paar minuten sprechzeit . nur privat resept . termin unp\\xc3\\xbcnklich , obwohl sie p\\xc3\\xbcnktlich da sind , m\\xc3\\xbcssen sie min min warten f\\xc3\\xbcr min gesprech .',\n",
      "       b'ich hatte schwierigkeiten nach einer operation zu heilen . die wunde war sehr ger\\xc3\\xb6tet und schmerzhaft , man sagte mir , es sei normal und die wunde sei v\\xc3\\xb6llig gereizt .',\n",
      "       b'sch\\xc3\\xb6n , dass es diese seite gibt ! endlich kann ich dieser \\xc3\\xa4rztin f\\xc3\\xbcr jahre professionelle beratung f\\xc3\\xbcr unsere familie auf diesem wege ein kleines dankesch\\xc3\\xb6n sagen . egal , ob unsere kinder hautversorgt werden mussten oder ob diverse zeckenbisse usw . usw . bei den gro\\xc3\\x9feltern . frau dr. bluth ist immer sehr zugewandt , ihre freundliche art schenkt vertrauen . auch zu aktuellen entwicklungen ist sie durch fortbildungen hab ick an den urkunden auch gesehen in der praxis auf dem laufenden . das personal ist flott nett , kann super blut nehmen praxis geschmackvoll , modern , toll erreichbar',\n",
      "       b'dr. thiemann kam sofort innerhalb weniger stunden zu meiner mutter zum hausbesuch , obwohl ganz neue patientin',\n",
      "       b'von einer konsultation bei diesem arzt kann ich nur dringend abraten . bei meinem an demenz erkrankten mann musste eine blasenspiegelung vorgenommen werden . eine sehr sensible untersuchung , die schon f\\xc3\\xbcr einen gesunden menschen belastend ist . die bet\\xc3\\xa4ubungsspritze machte eine junge arzthelferin , den arzt hatten wir bis dahin noch nicht zu gesicht bekommen . als es komplikationen gab , ging die arzthelferin zum arzt , kam wieder alleine zur\\xc3\\xbcck und versuchte es ein zweites mal . danach kam dr. bieber rein , ohne begr\\xc3\\xbc\\xc3\\x9fung , weder verbal noch mit handschlag und ohne blickkontakt zu uns und schimpfte gleich los , also ich wei\\xc3\\x9f ja nicht , ob das was wird ! auf meine antwort , dass da wohl seine kunstfertigkeit gefragt sei , reagierte er heftig . offensichtlich wertete er meine bemerkung als infragestellen seiner kompetenz . ohne in irgendeiner form sich mit meinem mann in kontakt zu setzen , nahm er die blasenspiegelung vor , die abgebrochen werden musste , da die schmerzen f\\xc3\\xbcr meinen mann zu gro\\xc3\\x9f wurden . der w\\xc3\\xbctende kommentar des arztes war , dass er das ja gleich gesagt habe . auf meine entgegnung , dass sei ja auch kein wunder , wenn im vorfeld keine vertrauensbasis hergestellt worden sei und er ihn nicht einmal gegr\\xc3\\xbc\\xc3\\x9ft habe , entgegnete er das sind kinkerlitzchen , mit so was gebe ich mich nicht ab ! tja , ein armutszeugnis was gibt es da noch zu sagen ? respektlos und ohne jegliche empathie !',\n",
      "       b'die beiden sprechstundenhilfen unprofessionell und diskutieren \\xc3\\xbcber die \\xc3\\xbcberweisung . auf der \\xc3\\xbcberweisung stand genau was erbeten wird dies wurde als teilweise unsinnig von der sprechstundenhilfe gesehen befunde wurden ungefragt kommentiert und tips gegeben zum krankheitsbild , sowie negative prognosen mitgeteilt dies erwarte ich und m\\xc3\\xb6chte ich nicht von einer sprechstundenhilfe die \\xc3\\xa4rztin beantwortete meine fragen nicht die enddiagnose ist mir nun auch nicht klar nie wieder bin ich dort !',\n",
      "       b'nach den doch \\xc3\\xbcberwiegend nicht so positiven bewertungen war ich mir nicht sicher , ob ich den termin zur darmspiegelung wahr nehmen sollte . ich tat es trotzdem und kann nur sagen , ich bin positiv \\xc3\\xbcberrascht worden . innerhalb von tagen hatte ich einen termin , am n\\xc3\\xa4chsten tag gleich zum vorbereitungstermin , der z\\xc3\\xbcgig und professionell ablief . ich wurde ausreichend aufgekl\\xc3\\xa4rt \\xc3\\xbcber den vorgang durch die super netten schwestern . der termin der spiegelung verlief reibungslos ohne gro\\xc3\\x9fe wartezeit , mit freundlichkeit der schwestern und ein noch kurzes vorab gespr\\xc3\\xa4ch mit dem doktor . die wartezeit nach der spiegelung war gering und das abschlussgespr\\xc3\\xa4ch mit dem doktor zwar kurz aber informativ und ausreichend meine n\\xc3\\xa4chsten termine dieser art werde ich wieder dort wahr nehmen .',\n",
      "       b'ich habe jetzt seit ca . jahren asthma und solange bin ich auch bei frau dr linnhoff in behandlung gewesen ! ! ! . ein termin bei frau dr linnhoff f\\xc3\\xa4ngt so an , dass man in der regel stunden warten darf , also immer am besten so fr\\xc3\\xbch wie m\\xc3\\xb6glich ein termin geben lassen , damit man keine stunden warten muss . dann werden einige tests durchgef\\xc3\\xbchrt bis man letztendlich zur \\xc3\\xa4rztin darf , die sich max . minuten f\\xc3\\xbcr einen zeit nimmt , keine frage beantwortet wie zb meine testergebnisse aussehen und einem nicht mal schafft in die augen zu schauen . ich habe ihr beim letzten mal erz\\xc3\\xa4hlt , dass ich angefangen habe zur hom\\xc3\\xb6pathie zugehen , um mein asthma ein bisschen besser in den griff zubekommen , sie hat angefangen mich an zubr\\xc3\\xbcllen , dass es eine frechtheit w\\xc3\\xa4re und ihr respektlos gegen\\xc3\\xbcber w\\xc3\\xa4re , da ich bei ihr in behandlung sei , mein leben gef\\xc3\\xa4hrden w\\xc3\\xbcrde , meine hom\\xc3\\xb6ptahin mir b\\xc3\\xb6ses will und keine richtige \\xc3\\xa4rztin sei . ich kann verstehen , dass sie als lungen\\xc3\\xa4rtzin misstrauisch ist was hom\\xc3\\xb6pathische behandlungen angeht , sie hat aber kein recht dazu , sich mich so b\\xc3\\xb6sartig anzugreifen , mich und meine hom\\xc3\\xb6pathin zu beleidigen , wenn sie sich jedes halbe jahr minuten f\\xc3\\xbcr mich zeit nimmt und nicht mal dann sich wirklich mit mir zubesch\\xc3\\xa4ftigen . man kann mit mir \\xc3\\xbcber alles reden und ich lasse mir auch gerne in einem normalen angemessenen ton erkl\\xc3\\xa4ren , warum hom\\xc3\\xb6pathie bei asthma nicht der richtige weg sei . ich werde mir jetzt aufjedenfall eine neue \\xc3\\xa4rztin suchen , da ich von dr. linnhoff sehr entt\\xc3\\xa4uscht bin , so geht man nicht mit menschen um ! ps die arzthelferinnen sind alle super lieb und zuvorkommend , .. die armen ... !',\n",
      "       b'die behandlung geht ein nur schnell schnell schnell . man geht nicht auf den patienten ein . musste dreimal wieder kommen , weil immer wieder die falschen werte f\\xc3\\xbcr die brille aufgeschrieben worden sind . was ich sehr \\xc3\\xa4rgerlich fand . das empfangspersonal k\\xc3\\xb6nnte auch freundlicher sein . als patient hat man das gef\\xc3\\xbchl , das man als euro angesehen wird . es wird versucht , dem patient mit extra untersuchungen , dass geld aus der tasche zu ziehen .',\n",
      "       b'man frau f\\xc3\\xbchlt sich bei ihr gut betreut .',\n",
      "       b'ich war das erste mal bei dr wittekind mit einer klassischen , dicken erk\\xc3\\xa4ltung . da ich nat\\xc3\\xbcrlich keinen termin hatte , fuhr ich morgens ohne ank\\xc3\\xbcndigung zur praxis . die arzthelferin fragte , ob ich in der n\\xc3\\xa4he wohne , da es recht voll war . deshalb schickte sie mich zun\\xc3\\xa4chst nach hause , ich sollte eine stunde sp\\xc3\\xa4ter wiederkommen . fand ich gut , zu hause ists ja doch gem\\xc3\\xbctlicher als in einem vollen wartezimmer und ich kenne das auch durchaus anders . als ich dann wieder da war , bin ich auch schnell ins behandlungszimmer gekommen . dr wittekind begr\\xc3\\xbc\\xc3\\x9fte mich gleich sehr freundlich und ich f\\xc3\\xbchlte mich gut aufgehoben . nachdem er mir bei der schilderung meiner beschwerden zugeh\\xc3\\xb6rt und einige nachfragen gestellt hat , erkl\\xc3\\xa4rte er mir leicht verst\\xc3\\xa4ndlich die ursachen f\\xc3\\xbcr meine symptome und wie wir die jetzt behandeln w\\xc3\\xbcrden . falls es mir nicht besser gehen sollte , sollte ich auf jeden fall nochmal erscheinen . ich bin mit gutem gef\\xc3\\xbchl wieder nach hause gegangen und werde auch wiederkommen . der vollst\\xc3\\xa4ndigkeit halber die praxisr\\xc3\\xa4ume sind eher klein und auch schon etwas \\xc3\\xa4lter , aber f\\xc3\\xbcr mich sind das keine bewertungskriterien f\\xc3\\xbcr einen arzt',\n",
      "       b'wenn man einen guten arzt braucht , ist es nicht einfach , auch einen guten mediziner zu finden . ich hatte mit herrn dr. adler gl\\xc3\\xbcck . sofern ich die medizinische , fachliche kompetenz beurteilen kann , w\\xc3\\xbcrde ich herrn dr. adler jedem empfehlen , der medizinische hilfe braucht . es ist wohl auch die langj\\xc3\\xa4hrige erfahrung , die einen guten mediziner ausmacht . herr dr. adler ist nicht ein arzt der medikamente verschreibt , und wenn die nicht helfen , probiert man was anderes aus . ein volles wartezimmer ist wohl verst\\xc3\\xa4ndlich , wenn eine gute medizinische behandlung zu erwarten ist . eine ehrliche aussage vom arzt ist mir lieber , als in einer hightech praxis von ger\\xc3\\xa4t zu ger\\xc3\\xa4t geschoben zu werden . ich kann herrn dr. adler nur empfehlen .',\n",
      "       b'frau dr. feinen macht eine sehr gute und sehr einf\\xc3\\xbchlsame sprechstunde . sie untersuchte mich sehr sorgf\\xc3\\xa4ltig und dennocch vorsichtig . ich konnte mit ihr \\xc3\\xbcber alle belange sprechen , sie hatte auch ein offenes ohr f\\xc3\\xbcr alle meine fragen zur m\\xc3\\xa4nnlichen sexualit\\xc3\\xa4t . ich kann frau dr. feinen wie auch das gesamte praxisteam jedem uneingeschr\\xc3\\xa4nkt empfehlen',\n",
      "       b'war das erste mal da und das letzte mal ! zeigen keine korparation gegen \\xc3\\xbcber den patienten . ziemlich unfreundlich wenn man kein privat pat . ist .',\n",
      "       b'nach zwei falsch gestellten diagnosen habe ich gewechselt die \\xc3\\xa4rztin h\\xc3\\xb6rt nicht zu und ist sehr launisch .',\n",
      "       b'gestern hatte ich starke schmerzen in fu\\xc3\\x9f , knie und r\\xc3\\xbccken . deshalb bin ich einfach in die chirurgie gegangen , nach dem rat meines hausarztes , und obwohl es akut war , habe ich zweieinhalb stunden gewartet . die \\xc3\\xa4rztin ist sehr unfreundlich , ungeduldig und aggressiv . sie nimmt sich keine zeit , um genau zu h\\xc3\\xb6ren , was das problem ist , und hat weniger als minuten mit mir gedauert , leider ohne gute und vertrauliche behandlung . ich habe mehrmals gesagt , dass ich an bestimmten stellen schmerzen habe , aber sie hat es einfach nicht geglaubt ! ! ! sie war w\\xc3\\xa4hrend der untersuchung wirklich aggressiv ! ich bin \\xc3\\xbcberhaupt nicht zufrieden , und jetzt muss ich einen anderen professionellen physiker aufsuchen . ich f\\xc3\\xbchle mich durch die schlechte behandlung des arztes und des assistenten geistig zerrissen . das ist keine menschliche praxis !',\n",
      "       b'kompetent und zugewandt . hoher grad am vertreuensverh\\xc3\\xa4ltnis . behandlungsempfehlungen immer am notwendigen .',\n",
      "       b'zuerst musste ich monate warten auf den termin und dann haben sie von selber den termin verschoben , trotzdem musste ich in der praxis mehr als stunde warten , obwohl ich gesagt habe , dass ich zu arbeit muss . es gab kein verst\\xc3\\xa4ndnis und richtig lange wartezeit ! !',\n",
      "       b'sehr proffessionelle behandlung , versteht sein handwerk ausgezeichnet und nimmt sich zeit f\\xc3\\xbcr die behandlung .',\n",
      "       b'wie der vorredner alles wie am flei\\xc3\\x9fband . der beste spruch , den man im akutfall von einem arzt erwartet , wenn man noch eine frage hat , ist naja , eigentlich habe ich keine zeit mehr f\\xc3\\xbcr eine frage , weil mein wartezimmer voll ist ... wenns nicht so lange dauert , stellen sie ihre frage , ansonsten kommen sie nochmal wieder ! . toll , da f\\xc3\\xbchlt man sich wohl , da geht man gerne hin ! !',\n",
      "       b'sie hatte starke menstruationsblutungen , die pl\\xc3\\xb6tzlich anderthalb bis zwei wochen dauerten . sie machte weder einen bluttest f\\xc3\\xbcr ein jahr , um zu sehen , ob der blutverlust gef\\xc3\\xa4hrliche z\\xc3\\xbcge angenommen hatte , noch eine gr\\xc3\\xbcndliche sonographie ! sie dr\\xc3\\xbcckte mir hormontabletten in die hand , die nicht leichtfertig verschrieben werden sollten , und sagte immer wieder , dass es nur an den wechseljahren liegen k\\xc3\\xb6nne . gott sei dank wechselte ich zu einem anderen gyn\\xc3\\xa4kologen , der durch eine schnelle , aber gr\\xc3\\xbcndliche sonographie feststellte , dass ich im mutterleib ein gutartiges myoid hatte , das die starken blutungen w\\xc3\\xa4hrend der wechseljahre verursacht , und dass die starken blutungen sehr schnell und einfach durch harmlosere tabletten wie hormone gestoppt werden k\\xc3\\xb6nnen . w\\xc3\\xa4re ich l\\xc3\\xa4nger in dieser praxis geblieben , h\\xc3\\xa4tte ich verbluten k\\xc3\\xb6nnen , und wer wei\\xc3\\x9f , was die hormontabletten verursacht h\\xc3\\xa4tte , die ich sofort in',\n",
      "       b'negativ , anstatt den vorhandenen schieber zu ersetzen wollte man mir eine komplette unterkieferbr\\xc3\\xbccke vermitteln , bzw . irgendwelche zusatzimplantate . auf meine bitte bei der sprechstundenhilfe , mich nochmals mit der \\xc3\\xa4rztin beraten zu d\\xc3\\xbcrfen , obwohl ich einen behandlungstermin hatte , wurde schon von der sprechstundenhilfe br\\xc3\\xbcsk abgelehnt .',\n",
      "       b'nach monaten wartezeit ist es nicht gelungen mir zu helfen . ich kann nur empfehlen einen anderen arzt zu konsultieren . starke schwellungen und schmerzen im fu\\xc3\\x9f sind das resultat dieser \\xc3\\xa4u\\xc3\\x9ferst schwachen leistung . nur weg hier !',\n",
      "       b'\\xc3\\xbcber die krankheitsursache konnte der arzt nichts herausfinden . er erkl\\xc3\\xa4rt wenig man f\\xc3\\xbchlt sich nicht wie bei anderen \\xc3\\xa4rzten gut beraten . obwohl die arztpraxis in meiner n\\xc3\\xa4he ist , werde ich mir einen anderen kompetenteren arzt suchen . diesen arzt kann ich nicht empfehlen .',\n",
      "       b'kompetentes team von der anmeldung bis zu den \\xc3\\xa4rzten . schnell , humorvoll , gut gelaunt . sehr zu empfehlen !',\n",
      "       b'ich war nur da , da mein eigentlicher arzt geschlossen hatte ... er gab nur schnippische kommentare und stellte mich hin , als ob ich mir meine schmerzen ausgedacht h\\xc3\\xa4tte . netterweise verwies er darauf , dass ich doch das n\\xc3\\xa4chste mal wieder zu meinem arzt gehen solle ... zu ihm jedenfalls geh ich definitiv nicht mehr',\n",
      "       b'am empfangstresen wird man warm und freundlich empfangen , sowie kompetent \\xc3\\xbcber alle abl\\xc3\\xa4ufe aufgekl\\xc3\\xa4rt . wartezeit nie l\\xc3\\xa4nger als eine halbe stunde . frau dr. homrighausen ber\\xc3\\xa4t und untersucht einf\\xc3\\xbchlsam , freundlich und sehr ausf\\xc3\\xbchrlich . ich kann , auch nach mehreren besuchen , diese praxis im kompletten nur weiter empfehlen !',\n",
      "       b'leider geht die \\xc3\\xa4rztin nicht auf ihre kleinen patienten ein zudem verschreibt sie hustensaft f\\xc3\\xbcr mein monate altes kind der ausschlie\\xc3\\x9flich f\\xc3\\xbcr kinder ab jahre geeignet ist zudem diskdiskutiert lautstark wegen einem wichtigen medikament was sie so nicht ausstellen wollte und \\xc3\\xa4rzte im krankenhaus dar\\xc3\\xbcber nur den kopf sch\\xc3\\xbctteln und man f\\xc3\\xbchlt sich abgefertigt',\n",
      "       b'leider vollst\\xc3\\xa4ndig furchtbar , wenn man dr kempf leider ! ! ! ! aufsuchen muss , wenn dr. latzel in urlauf krankheit ist . arroganz f\\xc3\\xa4ngt schon bei der anmeldung an und im sprechzimmer geht es leider weiter hei\\xc3\\x9ft es eigentlich , dass \\xc3\\xa4rzte menschen helfen wollen sollen oder geht es nur darum , unangenehm zu reagieren , weil man notgedrungen hier bei der \\xc3\\xa4rztin hilfe sucht ? ? ? ? ?',\n",
      "       b'die k\\xc3\\xb6rperliche untersuchung war sehr schmerzhaft , er ignorierte meine aufforderung , vorsichtiger vorzugehen . nach der untersuchung blutete ich , was ich nach einer gyn\\xc3\\xa4kologischen untersuchung noch nie getan hatte . au\\xc3\\x9ferdem waren verschiedene aussagen \\xc3\\xbcber eine bestehende krankheit unangemessen , verletzend und v\\xc3\\xb6llig unangemessen . leider brach er den eid des hippokrates , dem patienten nicht zu schaden .',\n",
      "       b'als frau das erste mal schwanger und mit keinerlei infos einfach nachhause geschickt . man ist eben schwanger und gut . so nach dem motto irgendwann in einigen monaten kommt das kind . beachten muss man dabei nix . auch nicht auf nachfrage . man darf alles essen und alles machen . bin sehr entt\\xc3\\xa4uscht . der wechsel zu einer frauen\\xc3\\xa4rztin ganz in der n\\xc3\\xa4he war goldwert ! ! ! dort wird man betreut und f\\xc3\\xbcr voll genommen . bei fr . dr. kilavuz wird man nur solange nett betreut wie man nicht schwanger wird . keine gute einstellung ! ! !',\n",
      "       b'ich fand die atmosph\\xc3\\xa4re in der praxis sehr freundlich und der arzt selbst , aber auch die arzthelferinnen konnten alle meine fragen freundlich und verst\\xc3\\xa4ndlich beantworten',\n",
      "       b'ich bin seit einigen jahren bei ihm gewesen auf empfehlung eines freundes . die erstenbeidentermine liefen freundlich , interessiert . er nahmsich zeit f\\xc3\\xbcr mich und meine sorgen . nur ein jahr sp\\xc3\\xa4ter wurde bei einer routineuntersuchung ein schilddr\\xc3\\xbcsenproblem festgestellt . ich bekam medikamente obwohl ich nebenwirkungen bef\\xc3\\xbcrchtete . da wurde ich schon darauf hingewiesen dass es sein muss . egal wie es mir dabei ginge . kurze abfertigung in knapp min . dennoch empfahl ich ihn weiter und ging doch nocheinmal hin , wegen einer anderen sache . nach std . wartens mit termin kam ich dran . ich schilderte meine angst , wurde nicht mal untersucht , rezept f\\xc3\\xbcr orthop\\xc3\\xa4die in die hand gedr\\xc3\\xbcckt , ohne erkl\\xc3\\xa4rung was zu tun ist , ohnetsch\\xc3\\xbc\\xc3\\x9f im raum stehen gelassen . dieses gespr\\xc3\\xa4ch dauerte zwei minuten . frage nach der schilddr\\xc3\\xbcse ? nie und nimmer . die helferinnen interessierten sich auch nicht f\\xc3\\xbcr mich , keine begr\\xc3\\xbc\\xc3\\x9fung keine verabschiedung . das war dann . ich bin dann mal weg .',\n",
      "       b'ich habe mich selten so schlecht behandelt gef\\xc3\\xbchlt wie in der praxis von herrn dr. castenholz . das wartezimmer grenzt direkt an die einzelnen sprechzimmer . die sprechzimmer selbst haben nur eine glast\\xc3\\xbcr . eine weitere abgrenzung zum wartezimmer gibt es nicht . das f\\xc3\\xbchrt dazu , dass alle patientengespr\\xc3\\xa4che von den wartenden mitgeh\\xc3\\xb6rt werden k\\xc3\\xb6nnen . ich habe mich wirklich unwohl und befangen gef\\xc3\\xbchlt , da ich wusste , dass das gesamte wartezimmer mith\\xc3\\xb6ren kann . die anamnese wurde nicht von herrn dr. castenholz selbst durchgef\\xc3\\xbchrt , sondern von seiner sprechstundenhilfe , die mir nach erl\\xc3\\xa4uterung meiner beschwerden akute schmerzen im knie und wiederkehrende sehnenentz\\xc3\\xbcndungen in beiden armen in einem sehr ungeduldigen und unh\\xc3\\xb6flichen ton erkl\\xc3\\xa4rte , dass ich mich bittesch\\xc3\\xb6n f\\xc3\\xbcr eine beschwerde entscheiden m\\xc3\\xbcsse . sie k\\xc3\\xb6nnten hier ja nicht alles behandeln . als ich erkl\\xc3\\xa4rte , dass ich unter beiden beschwerden gleicherma\\xc3\\x9fen leide , wurde ich mit dem satz sie verstehen es einfach nicht ! angepampt . da blieb mir kurz die spucke weg vor schreck . da ich eine \\xc3\\xbcberweisung vom hausarzt hatte mit der bitte um \\xc3\\xbcberpr\\xc3\\xbcfung der halswirbels\\xc3\\xa4ule als m\\xc3\\xb6gliche ursache f\\xc3\\xbcr meine armbeschwerden , wurde ich dann doch zum r\\xc3\\xb6ntgen geschickt . als sich herr dr. castenholz endlich zeit f\\xc3\\xbcr mich nahm , musste ich alles noch einmal im schnelldurchlauf herunterrasseln . mein knie schaute er sich erst gar nicht an und verschrieb mir eine bandage . mein r\\xc3\\xb6tgenbild war unauff\\xc3\\xa4llig , also wurden die armbeschwerden auch ad acta gelegt . zum schluss hat er meinen hals eingerenkt . daraufhin bekam ich wahnsinnige schmerzen in nacken und schulterbereich , die nach einer woche immer noch andauern . insgesamt habe ich mich unwillkommen und unverstanden gef\\xc3\\xbchlt .',\n",
      "       b'ich fliege km um von ihr behandelt zu werden . ihre kleinen op narben verschwinden mit den jahren v\\xc3\\xb6llig . ich bin seit meiner grundschule bei ihr in behandlung , insbesondere gef\\xc3\\xa4llt mir ihre achtsamkeit und r\\xc3\\xbccksichtnahme im umgang mit den patienten . sie ist immer darauf bedacht keine zus\\xc3\\xa4tzlichen schmerzen zu verursachen und die bestm\\xc3\\xb6gliche heilung zu erzielen , auch wenn dies in manchen f\\xc3\\xa4llen kostspielig sein mag . sehr freundliche , verst\\xc3\\xa4ndnisvolle , fachkundige \\xc3\\xa4rztin .',\n",
      "       b'solch ein arroganter und oberfl\\xc3\\xa4chlicher arzt w\\xc3\\xbcrde nicht praktizieren d\\xc3\\xbcrfen .',\n",
      "       b'ich , als nicht patientin , durfte zwar ohne termin hinkommen , was in berlin ja eher seltener der fall ist ... die wartezeit war in dem fall angemessen , etwas \\xc3\\xbcber eine stunde . dann kam ich ins behandlungszimmer , erkl\\xc3\\xa4rte dem doc mein problem , doch dieser h\\xc3\\xb6rte mir kaum zu . er fragte mich etwas \\xc3\\xbcber meine l\\xc3\\xa4dierte hand , ich gab ihm eine antwort , in der ich die m\\xc3\\xb6gliche ursache erw\\xc3\\xa4hnte ... seine antwort h\\xc3\\xb6ren sie doch auf zu philosophieren ! dass ich wirklich schmerzen hatte , interessierte ihn nicht . im gegenteil ! zum abschied gab er mir die hand und dr\\xc3\\xbcckte beabsichtigt fest zu . als ich leicht in die knie ging und aua sagte , fing er an zu grinsen und meinte ich wollte nur mal sehen , ob wirklich weh tut . diagnose keine , ursache der schmerzen nicht gefunden , weitere ma\\xc3\\x9fnahmen \\xc3\\xbcberweisung zum r\\xc3\\xb6ntgen ein r\\xc3\\xb6ntgenbild existierte bereits ! . fazit v\\xc3\\xb6llig unn\\xc3\\xbctzer besuch , zeitverschwendung !',\n",
      "       b'sehr veraltete praxis um nicht zu sagen ungepflegt und mangelhaft ausgestattet . arzt nimmt sich kaum zeit f\\xc3\\xbcr eine untersuchung , h\\xc3\\xb6rt zudem nicht richtig hin ! sehr unprofessionell und man f\\xc3\\xbchlt sich nicht ernst genommen . nicht weiterzuempfehlen ! ! !',\n",
      "       b'sehr schlechte behandlung von oben nach unten , sehr unfreundlich und l\\xc3\\xb6st die probleme nicht .',\n",
      "       b'dr. mahmoud hat mir sehr geholfen . empfand ihn als kompetend , hatte ein offenes ohr f\\xc3\\xbcr meine belange . ich bin sehr zufrieden mit ihm .',\n",
      "       b'er geht sehr gut auf kinder ein . der beweis ist meine tochter . sie geht total gerne zu ihm .',\n",
      "       b'wurde mit einem akut entz\\xc3\\xbcndetem abszess \\xc3\\xbcberwiesen . durfte am n\\xc3\\xa4chsten tag direkt um kommen . habe bis uhr gewartet . \\xc3\\xa4rztin hat den abszess und die entz\\xc3\\xbcndung richtig diagnostiziert . nach min . wurde ich weggeschickt mit ml abgef\\xc3\\xbcllter creme und den worten , ,\\xc3\\xb6ffnung w\\xc3\\xa4re eine privatleistung . bei . hausarzt zur\\xc3\\xbcck wurde ich sofort zu einem anderen arzt geschickt . musste am selben tag noch operiert werden . h\\xc3\\xa4tte ich auf dr. hammer geh\\xc3\\xb6rt , w\\xc3\\xa4re ich ein paar tage sp\\xc3\\xa4ter im kh gelandet .',\n",
      "       b'tolle beratung , freundliches personal . sehr kompetent . zudem nettes ambiente . bin seit jahren patient und habe seitdem keine probleme mehr .',\n",
      "       b'falsche diagnose und danach auch falsche behandlung',\n",
      "       b'trotz termin , st. wartezeit . hektische , unfreundliche frau . f\\xc3\\xa4llt einem st\\xc3\\xa4ndig ins wort und findet patienten wehleidig und nervig . sehr ungeduldig und laut . leider musste ich die \\xc3\\xa4rztin wohl an ihrem schlechtesten tag erleben . schon beim erkl\\xc3\\xa4ren von meinem krankheitsbild unterbrach mich die \\xc3\\xa4rztin ungeduldig und gereizt . sie vergriff sich mehrmals im ton schrie mich sogar bewusst an bis ich aufstand und einfach ging .',\n",
      "       b'f\\xc3\\xbcr die erhaltung meines zahnes . jeder andere wollte ziehen und ein implantat setzen . so viel m\\xc3\\xbche gibt sich wohl sonst niemand mehr . ich habe mit jahren als angstpatient endlich meinen zahnarzt gefunden . es ist tats\\xc3\\xa4chlich der erste , zu dem ich wieder hingegangen bin . diese bewertung kann ich nur mit einem aufrichtigen dankesch\\xc3\\xb6n beenden .',\n",
      "       b'ich bin schon jahrelang bei ihr in behandlung , ich sch\\xc3\\xa4tze ihre ehrliche meinung !',\n",
      "       b'ich begleitete meine j\\xc3\\xa4hrige oma dieses jahr zu dr. naumburger . dieser ist schon seit vielen jahren ihr hausarzt , mal mehr mal weniger gut . nach einer unh\\xc3\\xb6flichen begr\\xc3\\xbc\\xc3\\x9fung warum bringen sie denn hier ihre angeh\\xc3\\xb6rigen mit . , wurde ich erfolgreich von ihm ignoriert , unsere fragen wurden von ihm wenig fachlich beantwortet . insgesamt wurden wir ziemlich abgeb\\xc3\\xbcgelt . meine oma war nach diesem besuch absolut verunsichert und ungl\\xc3\\xbccklich . das wird uns garantiert nicht noch einmal passieren . herr naumburger hat jetzt eine patientin weniger , denn sie hat sich nach diesem auftritt f\\xc3\\xbcr einen anderen hausarzt entschieden . sehr bezeichnend nach ihrem ersten termin beim neuen arzt sagte sie zu uns ja , das ist auch mal ein arzt gewesen . das sagt meines erachtens alles !',\n",
      "       b'ich kann die gesamte praxis insgesamt nur empfehlen . mein au\\xc3\\x9fenmeniskusriss wurde festgestellt durch dr schmidt aus der gleichen praxis . diesen m\\xc3\\xb6chte ich hier auch gleichzeitig ausdr\\xc3\\xbccklich mal loben und empfehlen . die operation wurde dann durch dr v\\xc3\\xa4terlein im marienkrankenhaus durchgef\\xc3\\xbchrt . dr v\\xc3\\xa4terlein kannte ich bis dato nicht . aber schon beim ersten termin zur op besprechung merkte ich , dass ich hier beim richtigen arzt bin . er hat eine sehr ruhige und kompetente art und austrahlung . mir wurde alles umfassend erkl\\xc3\\xa4rt und jede frage ausf\\xc3\\xbchrlich beantwortet . der tag im marienkrankenhaus verlief ebenfalls \\xc3\\xa4u\\xc3\\x9ferst professionell . das op ergebnis ist sehr zufriendenstellend . keine schmerzen . keine weiteren beschwerden .',\n",
      "       b'ich war anfang oktober in der praxis wegen einer geschwollenen wange . es wurde ger\\xc3\\xb6ngt jedoch wurde mir nicht geholfen . ich wurde an meinen zahnarzt verwiesen , obwohl der geschlossen hatte . am n\\xc3\\xa4chsten tag bin ich zu einem oralchirurgen , der mir sagte , dass ku den kiefer h\\xc3\\xa4tte \\xc3\\xb6ffnen m\\xc3\\xbcssen , damit der eiter abl\\xc3\\xa4uft . ich kann ku nicht weiterempfehlen .'],\n",
      "      dtype=object)>}\n",
      "tf.Tensor(\n",
      "[1 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 1 0 1 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1 0 1 0 1 1\n",
      " 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 1 0], shape=(128,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for text, labels in dataset_train.take(1):\n",
    "    print(text)\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Umlaute seem to have strange encoding - let's test first to be sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'\\xc3\\xa4rzte f\\xc3\\xbcr \\xf0\\x9f\\x98\\x8a unbekanntes_wort sp\\xc3\\xa4ter', shape=(), dtype=string)\n",
      "tf.Tensor([168835  67730      1      1 156775], shape=(5,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "tensor = tf.constant(u\"ärzte für 😊 unbekanntes_wort später\")\n",
    "vec = params[\"computed_objects\"][\"vectorize_layer\"]\n",
    "\n",
    "print(tensor)\n",
    "print(vec(tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to be able to map the words correctly to meaningfull indices (except unknown words/signs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: The run you see below it from a build_model_cnn_simple(...) model (i.e. your output will look different)!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_vectorization (TextVect (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 300)         61647900  \n",
      "_________________________________________________________________\n",
      "conv_0 (Conv1D)              (None, None, 128)         268928    \n",
      "_________________________________________________________________\n",
      "max_pool_0 (MaxPooling1D)    (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv1D)              (None, None, 128)         114816    \n",
      "_________________________________________________________________\n",
      "global_max_pool_1 (GlobalMax (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "global_max_pool_dropout (Dro (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_dropout (Dropout)      (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "prediction (Dense)           (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 62,048,285\n",
      "Trainable params: 400,385\n",
      "Non-trainable params: 61,647,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model_cnn(params)\n",
    "#model = build_model_cnn_simple(params)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_model(params, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3512/3512 [==============================] - 623s 176ms/step - loss: 0.1947 - accuracy: 0.9307 - val_loss: 0.1585 - val_accuracy: 0.9491\n",
      "Epoch 2/10\n",
      " 469/3512 [===>..........................] - ETA: 8:37 - loss: 0.1655 - accuracy: 0.9432"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-de53e3b75364>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"training_epochs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-c9b775a0e050>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(params, model, dataset_train, dataset_val)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;31m#callbacks=[tensorboard_callback],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         epochs=training_epochs)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \"\"\"\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1084\u001b[0m     \u001b[0;34m\"\"\"Updates the progbar.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_init_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1087\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# One-indexed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_maybe_init_progbar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m       \u001b[0;31m# step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       self.stateful_metrics = self.stateful_metrics.union(\n\u001b[0;32m-> 1063\u001b[0;31m           set(m.name for m in self.model.metrics))\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mmetrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flatten_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m       \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_flatten_layers\u001b[0;34m(self, recursive, include_self)\u001b[0m\n\u001b[1;32m   2855\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_flatten_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_self\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2856\u001b[0m     for m in self._flatten_modules(\n\u001b[0;32m-> 2857\u001b[0;31m         recursive=recursive, include_self=include_self):\n\u001b[0m\u001b[1;32m   2858\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2859\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_flatten_modules\u001b[0;34m(self, recursive, include_self)\u001b[0m\n\u001b[1;32m   2882\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrackable_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseen_object_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2883\u001b[0m           \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2884\u001b[0;31m         \u001b[0mseen_object_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrackable_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2886\u001b[0m         \u001b[0;31m# Metrics are not considered part of the Layer's topology.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params[\"training_epochs\"] = 10\n",
    "history = train_model(params, model, dataset_train, dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a8489d1127d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite overfitted. Training could stop after ~3 epochs and some regularizations (like dropout) could also make sense.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c672dd955e2159a7\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c672dd955e2159a7\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Node: Following output is from a build_model_cnn(...) run!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if it is possible to further improve the model by unfreezing the embedding layer.\n",
    "\n",
    "Also see https://www.tensorflow.org/guide/keras/transfer_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_vectorization (TextVect (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 300)         61647900  \n",
      "_________________________________________________________________\n",
      "conv_0 (Conv1D)              (None, None, 128)         268928    \n",
      "_________________________________________________________________\n",
      "max_pool_0 (MaxPooling1D)    (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv1D)              (None, None, 128)         114816    \n",
      "_________________________________________________________________\n",
      "global_max_pool_1 (GlobalMax (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "global_max_pool_dropout (Dro (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_dropout (Dropout)      (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "prediction (Dense)           (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 62,048,285\n",
      "Trainable params: 62,048,285\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Unfreeze all layers (i.e. make embeddings trainable)\n",
    "model.trainable = True\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_compile_model(params, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3512/3512 [==============================] - 1652s 470ms/step - loss: 0.1120 - accuracy: 0.9625 - val_loss: 0.1005 - val_accuracy: 0.9659\n",
      "Epoch 2/2\n",
      "3512/3512 [==============================] - 1658s 472ms/step - loss: 0.0911 - accuracy: 0.9701 - val_loss: 0.0910 - val_accuracy: 0.9697\n"
     ]
    }
   ],
   "source": [
    "params[\"training_epochs\"] = 2\n",
    "history = train_model(params, model, dataset_train, dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title='', percentage=True, filename=None):\n",
    "    \"\"\"Plots or stores the confusion matrix \n",
    "\n",
    "    Parameters: \n",
    "        y_true: list/array\n",
    "            The true labels\n",
    "        y_pred: list/array\n",
    "            The predicted labels\n",
    "        title: str\n",
    "            The title of the plot\n",
    "        percentage: bool \n",
    "            Defines if percentage or number of samples should be printed for each category\n",
    "        filename: str\n",
    "            The path and name of the file to save the confusion matrix (will not be plotted to the screen if set)\n",
    "    \"\"\"\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    classes = list(set(list(y_true) + list(y_pred)))\n",
    "    classes.sort()\n",
    "\n",
    "    cmm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    print('Set Population: {}'.format(cmm.sum()))\n",
    "    print('Accuracy: {:.4f}'.format(float(cmm.trace()) / cmm.sum()))\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(np.flip(cmm / cmm.sum(), 0), interpolation='nearest', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.ylim(-0.5, len(classes)-0.5)\n",
    "\n",
    "    if classes is not None:\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        plt.xticks(tick_marks, classes, rotation=45, size='x-large')\n",
    "        plt.yticks(np.flip(tick_marks), classes, size='x-large')\n",
    "\n",
    "    cmm_flip = np.flip(cmm, 0)\n",
    "    for y in range(cmm.shape[0]):\n",
    "        for x in range(cmm.shape[1]):\n",
    "            if cmm_flip[y, x] > 0:\n",
    "                if percentage:\n",
    "                    plt.text(x, y, '%.3f' % ((cmm_flip[y, x] / cmm.sum())),\n",
    "                         horizontalalignment='center',\n",
    "                         verticalalignment='center')\n",
    "                else:\n",
    "                    plt.text(x, y, '%.0i' % cmm_flip[y, x],\n",
    "                         horizontalalignment='center',\n",
    "                         verticalalignment='center')\n",
    "    \n",
    "    if filename is not None:\n",
    "        plt.savefig(filename, dpi=300)\n",
    "    else: \n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def predict_classification(params, data, model):\n",
    "    \"\"\"Predicts the classes \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        The dictionary containing the parameters\n",
    "    data: dataframe\n",
    "        The data\n",
    "    model: model\n",
    "        The keras model\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    lists/arrays\n",
    "        The true labels (ground truth), the predicted labels, and the prediction probabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    import numpy as np\n",
    "        \n",
    "    batch_size = 2 * params.get(\"batch_size\", 64)\n",
    "    y_column_name = params.get(\"y_column_name\", \"label\")\n",
    "    X_column_name = params.get(\"X_column_name\", \"text_clean\")\n",
    "    prediction_probability_threshold = params.get(\"prediction_probability_threshold\", 0.5)\n",
    "    computed_objects_column_name = params.get(\"computed_objects_column_name\", \"computed_objects\")\n",
    "    label_binarizer = params[computed_objects_column_name][\"label_binarizer\"]\n",
    "    \n",
    "    y = data[y_column_name]\n",
    "    \n",
    "    y_pred_prob = model.predict(data[X_column_name], batch_size=batch_size)\n",
    "    y_pred = label_binarizer.inverse_transform(y_pred_prob, threshold=prediction_probability_threshold)                                             \n",
    "    \n",
    "    params[\"labels\"] = y\n",
    "    params[\"labels_predicted\"] = y_pred\n",
    "    params[\"labels_predicted_probability\"] = y_pred_prob\n",
    "    \n",
    "    return (y, y_pred, y_pred_prob)\n",
    "\n",
    "\n",
    "def report_classification_results(params, data, model):\n",
    "    \"\"\"Reports all classification results\n",
    "\n",
    "    Parameters: \n",
    "        params: dict\n",
    "            The dictionary containing the parameters\n",
    "        data: dataframe\n",
    "            The data\n",
    "        model: model\n",
    "            The keras model\n",
    "    \"\"\"\n",
    "    \n",
    "    from sklearn.metrics import classification_report\n",
    "    \n",
    "    verbose = params.get(\"verbose\", False)\n",
    "    path = params.get(\"model_path\")\n",
    "\n",
    "    y, y_pred, y_pred_prob = predict_classification(params, data, model)\n",
    "    \n",
    "    if path is not None:\n",
    "        path_confusion_matrix = os.path.join(path, \"confusion_matrix.png\")\n",
    "        plot_confusion_matrix(y, y_pred, filename=path_confusion_matrix)\n",
    "    if verbose:\n",
    "        plot_confusion_matrix(y, y_pred)\n",
    "        \n",
    "    if path is not None:\n",
    "        path_classification_report = os.path.join(path, \"classification_report.csv\")\n",
    "        report = classification_report(y, y_pred, output_dict=True)\n",
    "        report = pandas.DataFrame(report).transpose()\n",
    "        report.to_csv(path_classification_report)\n",
    "    if verbose:\n",
    "        report = classification_report(y, y_pred)\n",
    "        print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check performance on all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set Population: 331187\n",
      "Accuracy: 0.9511\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      1.00      0.80     33022\n",
      "    positive       1.00      0.95      0.97    298165\n",
      "\n",
      "    accuracy                           0.95    331187\n",
      "   macro avg       0.84      0.97      0.89    331187\n",
      "weighted avg       0.97      0.95      0.96    331187\n",
      "\n",
      "CPU times: user 1min 57s, sys: 755 ms, total: 1min 58s\n",
      "Wall time: 57.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "report_classification_results(params, data, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check performance on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set Population: 66238\n",
      "Accuracy: 0.9434\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      1.00      0.78      6604\n",
      "    positive       1.00      0.94      0.97     59634\n",
      "\n",
      "    accuracy                           0.94     66238\n",
      "   macro avg       0.82      0.97      0.87     66238\n",
      "weighted avg       0.96      0.94      0.95     66238\n",
      "\n",
      "CPU times: user 20.8 s, sys: 120 ms, total: 20.9 s\n",
      "Wall time: 8.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "report_classification_results(params, data_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
